"""
å³åˆ»åˆ†ææŠ¥å‘Šç”Ÿæˆå™¨
å®ç°å››ç±»æŠ¥å‘Šï¼š
- daily_hotspot: 24å°æ—¶çƒ­ç‚¹è¿½è¸ªå™¨
- weekly_digest: å‘¨åº¦ç¤¾ç¾¤æ´å¯Ÿæ‘˜è¦
- kol_trajectory: æœˆåº¦KOLæ€æƒ³è½¨è¿¹å›¾ï¼ˆå¯å¹¶å‘å¤šç”¨æˆ·ï¼‰
- quarterly_narrative: å­£åº¦æˆ˜ç•¥å™äº‹åˆ†æ

è¾“å‡ºä¿å­˜è‡³ jk_reports è¡¨,å¹¶åœ¨æŠ¥å‘Šä¸­é™„å¸¦æ¥æºæ¸…å•ã€‚
"""
from __future__ import annotations

import logging
from typing import Any, Dict, List, Optional, Tuple
from datetime import datetime, timezone, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed

try:
    from .database import DatabaseManager
    from .config import config
    from .llm_client import llm_client
except ImportError:  # pragma: no cover
    from database import DatabaseManager  # type: ignore
    from config import config  # type: ignore
    from llm_client import llm_client  # type: ignore


class JKReportGenerator:
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.db = DatabaseManager(config)
        self.llm_cfg = config.get_llm_config()
        self.analysis_cfg = config.get_analysis_config()
        self.max_content_length = int(self.llm_cfg.get('max_content_length', 380000))
        self.max_llm_concurrency = 3  # ä¸linuxdoä¿æŒä¸€è‡´,ä¸ä»[llm]è¯»å–

    def _bj_time(self) -> datetime:
        return datetime.now(timezone.utc) + timedelta(hours=8)

    # ---------- æ•°æ®å‡†å¤‡ä¸æ ¼å¼åŒ– ----------
    def _truncate(self, text: str, max_len: int) -> str:
        if not text:
            return ""
        if len(text) <= max_len:
            return text
        t = text[:max_len]
        # å°è¯•åœ¨å¥å°¾æˆªæ–­
        for d in ['ã€‚', '!', '?', '.', '!', '?', '\n']:
            pos = t.rfind(d)
            if pos > max_len * 0.7:
                return t[:pos + 1] + "\n..."
        return t + "\n..."

    def _clean_llm_output_for_notion(self, llm_output: str) -> str:
        """æ¸…ç†LLMè¾“å‡ºå†…å®¹ï¼Œç¡®ä¿Notionå…¼å®¹æ€§"""
        if not llm_output:
            return ""

        # ä¿æŠ¤Sourceå¼•ç”¨æ ¼å¼ï¼Œä¸è¦æ›¿æ¢å…¶ä¸­çš„æ–¹æ‹¬å·
        import re

        # å…ˆæå–æ‰€æœ‰Sourceå¼•ç”¨
        source_pattern = r'\[Sources?:\s*[T\d\s,]+\]'
        sources = re.findall(source_pattern, llm_output)

        # ä¸´æ—¶æ›¿æ¢Sourceå¼•ç”¨ä¸ºå ä½ç¬¦
        temp_llm_output = llm_output
        source_placeholders = {}
        for i, source in enumerate(sources):
            placeholder = f"__SOURCE_PLACEHOLDER_{i}__"
            source_placeholders[placeholder] = source
            temp_llm_output = temp_llm_output.replace(source, placeholder)

        # æ›¿æ¢å…¶ä»–å¯èƒ½å¯¼è‡´Markdowné“¾æ¥å†²çªçš„æ–¹æ‹¬å·
        cleaned = temp_llm_output.replace('[', 'ã€').replace(']', 'ã€‘')

        # æ¢å¤Sourceå¼•ç”¨
        for placeholder, original_source in source_placeholders.items():
            cleaned = cleaned.replace(placeholder, original_source)

        # ç¡®ä¿è¡Œå°¾æœ‰é€‚å½“çš„ç©ºæ ¼ç”¨äºæ¢è¡Œ
        lines = cleaned.split('\n')
        processed_lines = []

        for line in lines:
            # å¯¹äºä»¥*å¼€å¤´çš„æ–œä½“è¡Œï¼Œåœ¨è¡Œå°¾æ·»åŠ ç©ºæ ¼ä»¥ç¡®ä¿æ¢è¡Œ
            if line.strip().startswith('*') and line.strip().endswith('*'):
                processed_lines.append(line.rstrip() + '  ')
            else:
                processed_lines.append(line)

        return '\n'.join(processed_lines)

    def _format_posts_for_llm(self, posts: List[Dict[str, Any]], source_prefix: str = 'T') -> Tuple[str, List[Dict[str, Any]]]:
        """å°†å¸–å­æ ¼å¼åŒ–ä¸ºå¸¦ç¼–å·çš„Markdownæ–‡æœ¬ï¼ŒåŒ…å«åŸå§‹å†…å®¹å’Œè§£è¯»ä¿¡æ¯ï¼Œè¿”å›(æ–‡æœ¬, æºæ˜ å°„åˆ—è¡¨)"""
        lines: List[str] = []
        sources: List[Dict[str, Any]] = []
        total_chars = 0

        for idx, p in enumerate(posts, 1):
            sid = f"{source_prefix}{idx}"
            nickname = p.get('nickname') or p.get('jike_user_id') or 'æœªçŸ¥ä½œè€…'
            link = p.get('link') or ''
            title = p.get('title') or ''
            summary = p.get('summary') or ''
            pub = p.get('published_at')
            pub_str = pub.strftime('%Y-%m-%d %H:%M') if pub else ''

            # è·å–è§£è¯»ä¿¡æ¯
            interpretation_text = p.get('interpretation_text') or ''
            interpretation_model = p.get('interpretation_model') or ''

            # æ¯æ¡æ‘˜è¦æˆªæ–­,é¿å…å•æ¡è¿‡é•¿
            title_t = self._truncate(title, 140)
            summary_t = self._truncate(summary, 1500)

            # è§£è¯»å†…å®¹æˆªæ–­
            interpretation_t = self._truncate(interpretation_text, 3000) if interpretation_text else ''

            # æ„å»ºå¸–å­å—
            block = [
                f"### [{sid}] {title_t}",
                f"- ä½œè€…: {nickname}",
                f"- æ—¶é—´: {pub_str}",
                f"- é“¾æ¥: {link}",
                f"- åŸå§‹å†…å®¹:\n{summary_t}"
            ]

            # å¦‚æœæœ‰è§£è¯»å†…å®¹ï¼Œæ·»åŠ è§£è¯»éƒ¨åˆ†
            if interpretation_text:
                block.extend([
                    f"- AIæ·±åº¦è§£è¯» (æ¨¡å‹: {interpretation_model}):\n{interpretation_t}"
                ])
            else:
                block.extend([
                    "- AIæ·±åº¦è§£è¯»: æš‚æ— "
                ])

            block.append("")  # ç©ºè¡Œåˆ†éš”

            block_text = "\n".join(block)
            if total_chars + len(block_text) > self.max_content_length:
                self.logger.info(f"è¾¾åˆ°æœ€å¤§å†…å®¹é™åˆ¶({self.max_content_length}),æˆªæ–­å¸–å­åˆ—è¡¨äºç¬¬ {idx-1} æ¡")
                break
            lines.append(block_text)
            total_chars += len(block_text)
            sources.append({
                'sid': sid,
                'title': title_t,
                'link': link,
                'nickname': nickname,
                'excerpt': self._truncate(summary, 120)
            })

        return "\n".join(lines), sources

    def _render_sources_section(self, sources: List[Dict[str, Any]]) -> str:
        lines = ["## ğŸ“š æ¥æºæ¸…å• (Source List)", ""]
        for s in sources:
            # æ¸…ç†æ ‡é¢˜ä¸­çš„æ–¹æ‹¬å·ï¼Œé¿å…ä¸Markdowné“¾æ¥å†²çª
            clean_title = (s['title'] or s['excerpt']).replace('[', 'ã€').replace(']', 'ã€‘')
            lines.append(f"- **ã€{s['sid']}ã€‘**: [@{s['nickname']}]({s['link']}): {clean_title}")
        return "\n".join(lines)

    # ---------- Prompt æ¨¡æ¿ ----------
    def _prompt_daily(self) -> str:
        return """# Role: èµ„æ·±ç¤¾åŒºæˆ˜ç•¥åˆ†æå¸ˆ

# Context:
ä½ æ­£åœ¨åˆ†æä¸€ä¸ªç”±æŠ€æœ¯ä¸“å®¶ã€äº§å“ç»ç†ã€æŠ•èµ„äººå’Œåˆ›ä¸šè€…ç»„æˆçš„ç²¾è‹±ç¤¾åŒºâ€”â€”'å³åˆ»'åœ¨è¿‡å»24å°æ—¶å†…å‘å¸ƒçš„å¸–å­ã€‚ä½ çš„ä»»åŠ¡æ˜¯åŸºäºæˆ‘æä¾›çš„ã€å·²ç¼–å·çš„åŸå§‹è®¨è®ºææ–™å’ŒAIæ·±åº¦è§£è¯»ï¼Œæ’°å†™ä¸€ä»½ä¿¡æ¯å¯†åº¦é«˜ã€å†…å®¹è¯¦å°½ã€å¯è¯»æ€§å¼ºçš„æƒ…æŠ¥ç®€æŠ¥ã€‚

# Core Principles:
1.  **ä»·å€¼å¯¼å‘ä¸æ·±åº¦ä¼˜å…ˆ**: ä½ çš„æ ¸å¿ƒç›®æ ‡æ˜¯æŒ–æ˜å‡ºå¯¹ä»ä¸šè€…æœ‰ç›´æ¥ä»·å€¼çš„ä¿¡æ¯ã€‚åœ¨æ’°å†™æ¯ä¸ªéƒ¨åˆ†æ—¶ï¼Œéƒ½åº”è¿½æ±‚å†…å®¹çš„**æ·±åº¦å’Œå®Œæ•´æ€§**ï¼Œ**é¿å…è¿‡äºç®€çŸ­çš„æ¦‚æ‹¬**ã€‚
2.  **å¿ äºåŸæ–‡ä¸å¯è¿½æº¯æ€§ (CRITICAL)**: æ‰€æœ‰åˆ†æéƒ½å¿…é¡»åŸºäºåŸæ–‡ï¼Œå¹¶ä¸”æ¯ä¸€æ¡ç»“è®ºéƒ½å¿…é¡»åœ¨å¥æœ«ä½¿ç”¨ `[Source: T_n]` æˆ– `[Sources: T_n, T_m]` çš„æ ¼å¼æ˜ç¡®æ ‡æ³¨æ¥æºã€‚è¿™æ˜¯ç¡¬æ€§è¦æ±‚,ç»å¯¹ä¸èƒ½é—æ¼ã€‚
3.  **è¯†åˆ«å¸–å­ç±»å‹**: åœ¨åˆ†ææ—¶ï¼Œè¯·æ³¨æ„è¯†åˆ«æ¯ä¸ªä¸»é¢˜çš„æ½œåœ¨ç±»å‹ï¼Œä¾‹å¦‚ï¼š`[AI/å‰æ²¿æŠ€æœ¯]`, `[äº§å“ä¸è®¾è®¡]`, `[åˆ›ä¸šä¸æŠ•èµ„]`, `[ä¸ªäººæˆé•¿ä¸æ€è€ƒ]`, `[è¡Œä¸šä¸å¸‚åœºåŠ¨æ€]`, `[å·¥å…·ä¸å·¥ä½œæµåˆ†äº«]`ç­‰ã€‚è¿™æœ‰åŠ©äºä½ åˆ¤æ–­å…¶æ ¸å¿ƒä»·å€¼ã€‚

---

# Input Data:
ä»¥ä¸‹æ˜¯å³åˆ»ç¤¾åŒºçš„å¸–å­æ•°æ®ï¼Œæ¯æ¡å¸–å­åŒ…å«åŸå§‹å†…å®¹å’ŒAIæ·±åº¦è§£è¯»ï¼ˆå¦‚æœ‰ï¼‰ã€‚è¯·ç»¼åˆåˆ©ç”¨åŸå§‹å†…å®¹å’ŒAIè§£è¯»ä¿¡æ¯è¿›è¡Œåˆ†æï¼š
# å¸–å­æ•°æ® (åŸå§‹å†…å®¹ + AIè§£è¯»ï¼Œå·²ç¼–å·):
{content}

---

# Your Task:
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ç»“æ„å’Œè¦æ±‚ï¼Œç”Ÿæˆä¸€ä»½å†…å®¹ä¸°å¯Œè¯¦å®çš„å®Œæ•´MarkdownæŠ¥å‘Šã€‚

**ç¬¬ä¸€éƒ¨åˆ†ï¼šæœ¬æ—¶æ®µç„¦ç‚¹é€ŸæŠ¥ (Top Topics Overview)**
*   ä»»åŠ¡ï¼šé€šè¯»æ‰€æœ‰ææ–™ï¼Œä¸ºæ¯ä¸ªå€¼å¾—å…³æ³¨çš„çƒ­é—¨ä¸»é¢˜æ’°å†™ä¸€ä»½**è¯¦ç»†æ‘˜è¦**ã€‚
*   è¦æ±‚ï¼šä¸ä»…è¦æ€»ç»“ä¸»é¢˜çš„æ ¸å¿ƒå†…å®¹ï¼Œè¿˜è¦**å°½å¯èƒ½åˆ—å‡ºä¸»è¦çš„è®¨è®ºæ–¹å‘å’Œå…³é”®å›å¤çš„è§‚ç‚¹**ã€‚ç¯‡å¹…æ— éœ€ä¸¥æ ¼é™åˆ¶ï¼ŒåŠ›æ±‚å…¨é¢ã€‚

**ç¬¬äºŒéƒ¨åˆ†ï¼šæ ¸å¿ƒæ´å¯Ÿä¸è¶‹åŠ¿ (Executive Summary & Trends)**
*   ä»»åŠ¡ï¼šåŸºäºç¬¬ä¸€éƒ¨åˆ†çš„æ‰€æœ‰ä¿¡æ¯ï¼Œä»å…¨å±€è§†è§’æç‚¼å‡ºå…³é”®æ´å¯Ÿä¸è¶‹åŠ¿ã€‚
*   è¦æ±‚ï¼š
    *   **æ ¸å¿ƒæ´å¯Ÿ**: **å°½å¯èƒ½å…¨é¢åœ°**æç‚¼ä½ å‘ç°çš„é‡è¦è¶‹åŠ¿æˆ–æ´å¯Ÿï¼Œå¹¶è¯¦ç»†é˜è¿°ï¼Œ**ä¸è¦å±€é™äºå°‘æ•°å‡ ç‚¹**ã€‚
    *   **æŠ€æœ¯é£å‘ä¸å·¥å…·ç®±**: **è¯¦ç»†åˆ—å‡ºå¹¶ä»‹ç»**è¢«çƒ­è®®çš„æ–°æŠ€æœ¯ã€æ–°æ¡†æ¶æˆ–å·¥å…·ã€‚å¯¹äºæ¯ä¸ªé¡¹ç›®ï¼Œè¯·æä¾›æ›´è¯¦å°½çš„æè¿°ï¼ŒåŒ…æ‹¬å…¶ç”¨é€”ã€ä¼˜ç‚¹ã€ä»¥åŠç¤¾åŒºè®¨è®ºä¸­çš„å…·ä½“è¯„ä»·ã€‚
    *   **ç¤¾åŒºçƒ­è®®ä¸éœ€æ±‚ç‚¹**: **è¯¦ç»†å±•å¼€**ç¤¾åŒºæ™®éå…³å¿ƒçš„è¯é¢˜ã€é‡åˆ°çš„ç—›ç‚¹æˆ–æ½œåœ¨çš„éœ€æ±‚ï¼Œè¯´æ˜å…¶èƒŒæ™¯ã€å½“å‰è®¨è®ºçš„ç„¦ç‚¹ä»¥åŠæ½œåœ¨çš„å½±å“ã€‚

**ç¬¬ä¸‰éƒ¨åˆ†ï¼šä»·å€¼ä¿¡æ¯æŒ–æ˜ (Valuable Information Mining)**
*   ä»»åŠ¡ï¼šæ·±å…¥æŒ–æ˜å¸–å­å’Œå›å¤ä¸­çš„é«˜ä»·å€¼ä¿¡æ¯ï¼Œå¹¶è¿›è¡Œè¯¦ç»†ä»‹ç»ã€‚
*   è¦æ±‚ï¼š
    *   **é«˜ä»·å€¼èµ„æº/å·¥å…·**: **è¯¦ç»†åˆ—å‡ºå¹¶ä»‹ç»**è®¨è®ºä¸­å‡ºç°çš„å¯ä»¥ç›´æ¥ä½¿ç”¨çš„è½¯ä»¶ã€åº“ã€APIã€å¼€æºé¡¹ç›®æˆ–å­¦ä¹ èµ„æ–™ã€‚åŒ…æ‹¬èµ„æºçš„é“¾æ¥ï¼ˆå¦‚æœåŸæ–‡æä¾›ï¼‰ã€ç”¨é€”å’Œç¤¾åŒºè¯„ä»·ã€‚
    *   **æœ‰è¶£è§‚ç‚¹/æ·±åº¦è®¨è®º**: **è¯¦ç»†é˜è¿°**é‚£äº›å¼•äººæ·±æ€ã€å…·æœ‰å¯å‘æ€§çš„ä¸ªäººè§‚ç‚¹æˆ–é«˜è´¨é‡çš„è®¨è®ºä¸²ã€‚åˆ†æè¯¥è§‚ç‚¹ä¸ºä½•é‡è¦æˆ–å…·æœ‰å¯å‘æ€§ï¼Œä»¥åŠå®ƒå¼•å‘äº†å“ªäº›åç»­è®¨è®ºã€‚

**ç¬¬å››éƒ¨åˆ†ï¼šè¡ŒåŠ¨å»ºè®® (Actionable Recommendations)**
*   ä»»åŠ¡ï¼šåŸºäºä»¥ä¸Šæ‰€æœ‰åˆ†æï¼Œä¸ºç¤¾åŒºä¸­çš„ä¸åŒè§’è‰²æä¾›ä¸°å¯Œä¸”å…·ä½“çš„å»ºè®®ã€‚
*   è¦æ±‚ï¼šå»ºè®®å¿…é¡»æœ‰é«˜åº¦çš„é’ˆå¯¹æ€§ï¼Œå¹¶é˜è¿°å…¶èƒŒåçš„é€»è¾‘å’Œé¢„æœŸæ•ˆæœã€‚
    *   **ç»™äº§å“ç»ç†çš„å»ºè®®**: ...
    *   **ç»™åˆ›ä¸šè€…/æŠ•èµ„è€…çš„å»ºè®®**: ...
    *   **ç»™æŠ€æœ¯ä»ä¸šè€…çš„å»ºè®®**: ...

---

# Output Format (Strictly follow this Markdown structure):

## ä¸€ã€æœ¬æ—¶æ®µç„¦ç‚¹é€ŸæŠ¥

### **1. [ä¸»é¢˜Açš„æ ‡é¢˜]**
*   **è¯¦ç»†æ‘˜è¦**: [è¯¦ç»†æ‘˜è¦è¯¥ä¸»é¢˜çš„æ ¸å¿ƒå†…å®¹ï¼Œå¹¶åˆ—å‡ºä¸»è¦çš„è®¨è®ºæ–¹å‘å’Œå…³é”®å›å¤çš„è§‚ç‚¹ã€‚ç¯‡å¹…æ— éœ€ä¸¥æ ¼é™åˆ¶ï¼ŒåŠ›æ±‚å…¨é¢ã€‚] [Source: T_n]

### **2. [ä¸»é¢˜Bçš„æ ‡é¢˜]**
*   **è¯¦ç»†æ‘˜è¦**: [åŒä¸Šã€‚] [Source: T_m]

...(ç½—åˆ—æ‰€æœ‰ä½ è®¤ä¸ºå€¼å¾—æŠ¥å‘Šçš„çƒ­é—¨ä¸»é¢˜)

---

## äºŒã€æ ¸å¿ƒæ´å¯Ÿä¸è¶‹åŠ¿

*   **æ ¸å¿ƒæ´å¯Ÿ**:
    *   [è¯¦ç»†é˜è¿°ä½ å‘ç°çš„ä¸€ä¸ªé‡è¦è¶‹åŠ¿æˆ–æ´å¯Ÿã€‚ä¾‹å¦‚ï¼šAI Agentçš„å®ç°å’Œåº”ç”¨æˆä¸ºæ–°çš„æŠ€æœ¯ç„¦ç‚¹ï¼Œç¤¾åŒºå†…æ¶Œç°äº†å¤šä¸ªå›´ç»•æ­¤å±•å¼€çš„å¼€æºé¡¹ç›®å’Œå®è·µè®¨è®ºï¼Œå…·ä½“è¡¨ç°åœ¨...] [Sources: T2, T9]
    *   [è¯¦ç»†é˜è¿°ç¬¬äºŒä¸ªé‡è¦æ´å¯Ÿã€‚] [Sources: T3, T7]
    *   ...(å°½å¯èƒ½å¤šåœ°åˆ—å‡ºæ´å¯Ÿ)

*   **æŠ€æœ¯é£å‘ä¸å·¥å…·ç®±**:
    *   **[æŠ€æœ¯/å·¥å…·A]**: [è¯¦ç»†ä»‹ç»å®ƒæ˜¯ä»€ä¹ˆï¼Œä¸ºä»€ä¹ˆå®ƒç°åœ¨å¾ˆçƒ­é—¨ï¼Œç¤¾åŒºæˆå‘˜å¦‚ä½•è¯„ä»·å®ƒï¼Œä»¥åŠå®ƒè§£å†³äº†ä»€ä¹ˆå…·ä½“é—®é¢˜ã€‚] [Source: T3]
    *   **[æŠ€æœ¯/å·¥å…·B]**: [åŒä¸Šã€‚] [Source: T7]
    *   ...(å°½å¯èƒ½å¤šåœ°åˆ—å‡ºæŠ€æœ¯/å·¥å…·)

*   **ç¤¾åŒºçƒ­è®®ä¸éœ€æ±‚ç‚¹**:
    *   **[çƒ­è®®è¯é¢˜A]**: [è¯¦ç»†å±•å¼€ä¸€ä¸ªè¢«å¹¿æ³›è®¨è®ºçš„è¯é¢˜ï¼Œä¾‹å¦‚â€œå¤§æ¨¡å‹åœ¨ç‰¹å®šåœºæ™¯ä¸‹çš„è½åœ°æˆæœ¬â€ï¼ŒåŒ…æ‹¬è®¨è®ºçš„èƒŒæ™¯ã€å„æ–¹è§‚ç‚¹ã€äº‰è®®ç‚¹ä»¥åŠå¯¹æœªæ¥çš„å±•æœ›ã€‚] [Source: T5]
    *   **[æ™®ééœ€æ±‚B]**: [è¯¦ç»†æ€»ç»“ä¸€ä¸ªæ™®éå­˜åœ¨çš„éœ€æ±‚ï¼Œä¾‹å¦‚â€œéœ€è¦æ›´ç¨³å®šã€æ›´ä¾¿å®œçš„GPUç®—åŠ›èµ„æºâ€ï¼Œå¹¶åˆ†æè¯¥éœ€æ±‚äº§ç”Ÿçš„åŸå› å’Œç¤¾åŒºæå‡ºçš„æ½œåœ¨è§£å†³æ–¹æ¡ˆã€‚] [Source: T10]
    *   ...(å°½å¯èƒ½å¤šåœ°åˆ—å‡ºè¯é¢˜/éœ€æ±‚)

---

## ä¸‰ã€ä»·å€¼ä¿¡æ¯æŒ–æ˜

*   **é«˜ä»·å€¼èµ„æº/å·¥å…·**:
    *   **[èµ„æº/å·¥å…·A]**: [è¯¦ç»†ä»‹ç»è¯¥èµ„æº/å·¥å…·ï¼ŒåŒ…æ‹¬å…¶åç§°ã€åŠŸèƒ½ã€ä¼˜ç‚¹ã€æ½œåœ¨ç¼ºç‚¹ä»¥åŠç¤¾åŒºæˆå‘˜åˆ†äº«çš„ä½¿ç”¨æŠ€å·§æˆ–ç»éªŒã€‚ä¾‹å¦‚ï¼š`XX-Agent-Framework` - ä¸€ä¸ªç”¨äºå¿«é€Ÿæ„å»ºAI Agentçš„å¼€æºæ¡†æ¶ï¼Œç¤¾åŒºåé¦ˆå…¶ä¼˜ç‚¹æ˜¯ä¸Šæ‰‹å¿«ã€æ–‡æ¡£å…¨ï¼Œä½†ç¼ºç‚¹æ˜¯...ã€‚] [Source: T2]
    *   **[èµ„æº/å·¥å…·B]**: [åŒä¸Šã€‚] [Source: T8]
    *   ...(å°½å¯èƒ½å¤šåœ°åˆ—å‡ºèµ„æº/å·¥å…·)

*   **æœ‰è¶£è§‚ç‚¹/æ·±åº¦è®¨è®º**:
    *   **[å…³äºâ€œXXâ€çš„è§‚ç‚¹]**: [è¯¦ç»†é˜è¿°ä¸€ä¸ªæœ‰å¯å‘æ€§çš„è§‚ç‚¹ï¼Œåˆ†æå…¶é‡è¦æ€§ï¼Œå¹¶æ€»ç»“å› æ­¤å¼•å‘çš„ç²¾å½©åç»­è®¨è®ºã€‚ä¾‹å¦‚ï¼šæœ‰ç”¨æˆ·è®¤ä¸ºï¼Œå½“å‰é˜¶æ®µçš„AIåº”ç”¨å¼€å‘ï¼Œå·¥ç¨‹åŒ–èƒ½åŠ›æ¯”ç®—æ³•åˆ›æ–°æ›´é‡è¦ã€‚è¿™ä¸€è§‚ç‚¹å¼•å‘äº†å…³äºâ€œç®—æ³•å·¥ç¨‹å¸ˆâ€ä¸â€œAIåº”ç”¨å·¥ç¨‹å¸ˆâ€èŒè´£è¾¹ç•Œçš„å¤§é‡è®¨è®ºï¼Œä¸»æµçœ‹æ³•æ˜¯...] [Source: T4]
    *   **[å…³äºâ€œYYâ€çš„è®¨è®º]**: [åŒä¸Šã€‚] [Source: T6]
    *   ...(å°½å¯èƒ½å¤šåœ°åˆ—å‡ºè§‚ç‚¹/è®¨è®º)

---

## å››ã€è¡ŒåŠ¨å»ºè®®

*   **ç»™äº§å“ç»ç†çš„å»ºè®®**:
    *   [å»ºè®®1ï¼š[æå‡ºå…·ä½“å»ºè®®]ã€‚ç†ç”±ä¸é¢„æœŸæ•ˆæœï¼š[é˜è¿°è¯¥å»ºè®®çš„é€»è¾‘ä¾æ®ï¼Œä»¥åŠé‡‡çº³åå¯èƒ½å¸¦æ¥çš„å¥½å¤„]ã€‚ä¾‹å¦‚ï¼šå»ºè®®å…³æ³¨ç¤¾åŒºä¸­å…³äºâ€œç”¨æˆ·ä½“éªŒæ–­ç‚¹â€çš„è®¨è®ºï¼Œè¿™å¯èƒ½æ˜¯ä¸‹ä¸€ä¸ªäº§å“åˆ›æ–°çš„åˆ‡å…¥ç‚¹ã€‚] [Sources: T2, T9]
    *   [å»ºè®®2ï¼š...]

*   **ç»™åˆ›ä¸šè€…/æŠ•èµ„è€…çš„å»ºè®®**:
    *   [å»ºè®®1. [æå‡ºå…·ä½“å»ºè®®]ã€‚ç†ç”±ä¸é¢„æœŸæ•ˆæœï¼š[é˜è¿°è¯¥å»ºè®®çš„é€»è¾‘ä¾æ®ï¼Œä»¥åŠé‡‡çº³åå¯èƒ½å¸¦æ¥çš„å¥½å¤„]ã€‚ä¾‹å¦‚ï¼šç¤¾åŒºå¯¹â€œå°æ¨¡å‹â€çš„å…´è¶£æ­£åœ¨å‡æ¸©ï¼Œè¿™å¯èƒ½æ„å‘³ç€åœ¨ç‰¹å®šå‚ç›´é¢†åŸŸå­˜åœ¨æ–°çš„åˆ›ä¸šæœºä¼šã€‚] [Source: T1]
    *   [å»ºè®®2ï¼š...]

*   **ç»™æŠ€æœ¯ä»ä¸šè€…çš„å»ºè®®**:
    *   [å»ºè®®1ï¼š[æå‡ºå…·ä½“å»ºè®®]ã€‚ç†ç”±ä¸é¢„æœŸæ•ˆæœï¼š[é˜è¿°è¯¥å»ºè®®çš„é€»è¾‘ä¾æ®ï¼Œä»¥åŠé‡‡çº³åå¯èƒ½å¸¦æ¥çš„å¥½å¤„]ã€‚ä¾‹å¦‚ï¼šå»ºè®®æ·±å…¥å­¦ä¹ ç¤¾åŒºçƒ­è®®çš„ `XXX` æ¡†æ¶ï¼ŒæŒæ¡åèƒ½æ˜¾è‘—æå‡é¡¹ç›®å¼€å‘èƒ½åŠ›å’Œæ±‚èŒç«äº‰åŠ›ã€‚] [Source: T3]
    *   [å»ºè®®2ï¼š...]
"""

    def _prompt_weekly(self) -> str:
        return (
            "# Role: èµ„æ·±ç¤¾ç¾¤æˆ˜ç•¥é¡¾é—®\n"
            "\n"
            "# Context:\n"
            "ä½ æ­£åœ¨ä¸ºä¸€ä»½é«˜ç«¯å†…å‚,åˆ†æä¸€ä¸ªç”±æŠ€æœ¯ä¸“å®¶ã€äº§å“ç»ç†å’Œåˆ›ä¸šè€…ç»„æˆçš„ç²¾è‹±ç¤¾åŒºåœ¨è¿‡å»ä¸€å‘¨çš„å…¨éƒ¨è®¨è®ºã€‚ä½ çš„ä»»åŠ¡æ˜¯å¤ç›˜ç¤¾åŒºç„¦ç‚¹,æ´å¯Ÿè¶‹åŠ¿,å¹¶ç»™å‡ºæˆ˜ç•¥æ€§é¢„åˆ¤ã€‚\n"
            "\n"
            "# Core Principles:\n"
            "1. æ‰€æœ‰è¦ç‚¹éœ€ç»“åˆç¼–å·æ¥æºæ ‡æ³¨ [Source: T_n] æˆ– [Sources: T_a, T_b]ã€‚\n"
            "2. æ³¨é‡å˜åŒ–ä¸è¶‹åŠ¿ï¼Œè€Œä¸ä»…æ˜¯ä¿¡æ¯ç½—åˆ—ã€‚\n"
            "3. å…³æ³¨ç¤¾åŒºç»“æ„åŒ–åˆ†å±‚ï¼šæŠ€æœ¯/äº§å“/åˆ›ä¸š/æŠ•èµ„/å·¥å…·/è¡Œä¸š/æ–‡åŒ–ç­‰ã€‚\n"
            "\n"
            "# Input Data (å·²ç¼–å·å¸–å­)ï¼š\n\n{content}\n\n"
            "# Your Task:\n"
            "è¯·æŒ‰å¦‚ä¸‹ç»“æ„è¾“å‡ºä¸€ä»½Markdownå‘¨æŠ¥ï¼š\n"
            "## ä¸€ã€å…³é”®ä¸»é¢˜å›é¡¾ (Top Topics)\n"
            "- ç”¨3-5æ¡æ€»ç»“æœ¬å‘¨æœ€å—å…³æ³¨çš„è¯é¢˜åŠç»“è®ºã€‚[Sources: ...]\n"
            "\n"
            "## äºŒã€é‡è¦æ´å¯Ÿä¸è¶‹åŠ¿ (Insights & Trends)\n"
            "- æç‚¼2-3æ¡è·¨ä¸»é¢˜æ´å¯Ÿï¼Œè¯´æ˜å…¶æˆå› ä¸å½±å“ã€‚[Sources: ...]\n"
            "- åˆ—ç¤ºæœ¬å‘¨å€¼å¾—å…³æ³¨çš„æ–°æŠ€æœ¯/æ–°å·¥å…·åŠç¤¾åŒºè¯„ä»·ã€‚[Sources: ...]\n"
            "\n"
            "## ä¸‰ã€ç»“æ„åŒ–åˆ†æ (Deep Dive)\n"
            "- ä»ä¾›ç»™ä¾§/éœ€æ±‚ä¾§/ç”Ÿæ€ä½/è·¯å¾„ä¾èµ–ç­‰è§†è§’è¿›è¡Œæ·±æŒ–ã€‚[Sources: ...]\n"
            "\n"
            "## å››ã€é¢å‘è§’è‰²çš„å»ºè®® (Actionables)\n"
            "- ç»™äº§å“ç»ç†/å¼€å‘è€…/åˆ›ä¸šè€…/æŠ•èµ„è€…å„1-2æ¡å¯æ‰§è¡Œå»ºè®®ã€‚[Sources: ...]\n"
        )

    # ---------- æŠ¥å‘Šç”Ÿæˆ ----------
    def _analyze_with_llm(self, content: str, prompt_template: str) -> Optional[Dict[str, Any]]:
        """è°ƒç”¨æ™ºèƒ½æ¨¡å‹è¿›è¡Œæ·±åº¦åˆ†æï¼Œå¤±è´¥æ—¶è¿”å›None"""
        try:
            if llm_client is None:
                return None
            # æ ¼å¼åŒ–æç¤ºè¯
            prompt = prompt_template.format(content=content)
            # ä½¿ç”¨æ™ºèƒ½æ¨¡å‹è¿›è¡Œå¤æ‚æŠ¥å‘Šç”Ÿæˆä»»åŠ¡
            res = llm_client.call_smart_model(prompt)
            if isinstance(res, dict) and res.get('success'):
                return res
            return None
        except Exception as e:  # å…œåº•ï¼Œé¿å…å½±å“ä¸»æµç¨‹
            self.logger.warning(f"æ™ºèƒ½æ¨¡å‹åˆ†æå¤±è´¥ï¼Œå°†å›é€€æœ¬åœ°æŠ¥å‘Š: {e}")
            return None

    def _make_fallback_report(
        self,
        header: str,
        posts: List[Dict[str, Any]],
        period_start: datetime,
        period_end: datetime,
        sources: List[Dict[str, Any]],
    ) -> str:
        lines: List[str] = []
        lines.append(header)
        lines.append("")
        lines.append(f"æ—¶é—´èŒƒå›´ï¼š{period_start.strftime('%Y-%m-%d %H:%M')} - {period_end.strftime('%Y-%m-%d %H:%M')}")
        lines.append("")
        lines.append("LLMåˆ†æä¸å¯ç”¨ï¼Œä»¥ä¸‹ä¸ºåŸºäºç´ æçš„å ä½æŠ¥å‘Šï¼š")
        lines.append("")
        lines.append("## çƒ­é—¨åŠ¨æ€æ¸…å• (Top Materials)")
        for idx, p in enumerate(posts[:30], 1):
            title = p.get('title') or '(æ— æ ‡é¢˜)'
            link = p.get('link') or ''
            nickname = p.get('nickname') or p.get('jike_user_id') or 'æœªçŸ¥ä½œè€…'
            lines.append(f"{idx}. {title} - @{nickname}  {link}")
        lines.append("")
        lines.append(self._render_sources_section(sources))
        return "\n".join(lines)

    def generate_daily_hotspot(self, hours_back: Optional[int] = None) -> Dict[str, Any]:
        hours = int(hours_back or self.analysis_cfg.get('hours_back_daily', 24))
        end_time = self._bj_time()
        start_time = end_time - timedelta(hours=hours)

        posts = self.db.get_recent_posts(hours_back=hours)
        if not posts:
            return {
                'success': False,
                'error': f'æœ€è¿‘{hours}å°æ—¶å†…æ— æ–°å¢åŠ¨æ€',
            }

        content_md, sources = self._format_posts_for_llm(posts, source_prefix='T')
        prompt = self._prompt_daily()
        llm_analysis_result = self._analyze_with_llm(content_md, prompt)

        if not llm_analysis_result:
            header = "# å³åˆ»24å°æ—¶çƒ­ç‚¹è¿½è¸ªå™¨ (å ä½ç‰ˆ)"
            report_content = self._make_fallback_report(header, posts, start_time, end_time, sources)
        else:
            llm_output = llm_analysis_result.get('content', '')
            # ä¸ºLLMç”Ÿæˆçš„æŠ¥å‘Šæ·»åŠ æ ‡å‡†å¤´éƒ¨ä¿¡æ¯
            beijing_time = self._bj_time()
            header_info = [
                f"# ğŸ“ˆ å³åˆ»24å°æ—¶çƒ­ç‚¹è¿½è¸ªå™¨",
                "",
                f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {beijing_time.strftime('%Y-%m-%d %H:%M:%S')}*  ",
                "",
                f"*æ•°æ®èŒƒå›´: {start_time.strftime('%Y-%m-%d %H:%M:%S')} - {end_time.strftime('%Y-%m-%d %H:%M:%S')}*  ",
                "",
                f"*åˆ†æåŠ¨æ€æ•°: {len(posts)} æ¡*",
                "",
                "---",
                ""
            ]

            # æ¸…ç†LLMè¾“å‡ºä¸­å¯èƒ½çš„æ ¼å¼é—®é¢˜
            cleaned_llm_output = self._clean_llm_output_for_notion(llm_output)

            sources_section = self._render_sources_section(sources)

            # æ„å»ºæŠ¥å‘Šå°¾éƒ¨
            footer_lines = ["", "---", ""]
            provider = llm_analysis_result.get('provider')
            model = llm_analysis_result.get('model')
            if provider:
                footer_lines.append(f"*åˆ†æå¼•æ“: {provider} ({model or 'unknown'})*")
            
            footer_lines.extend([
                "",
                f"ğŸ“Š **ç»Ÿè®¡æ‘˜è¦**: æœ¬æŠ¥å‘Šåˆ†æäº† {len(posts)} æ¡åŠ¨æ€",
                "",
                "*æœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒ*"
            ])
            footer_section = "\n".join(footer_lines)

            report_content = "\n".join(header_info) + cleaned_llm_output + "\n\n" + sources_section + footer_section

        title = f"å³åˆ»24hçƒ­ç‚¹è§‚å¯Ÿ - {end_time.strftime('%Y-%m-%d %H:%M')}"
        report_row = {
            'report_type': 'daily_hotspot',
            'scope': 'global',
            'analysis_period_start': start_time,
            'analysis_period_end': end_time,
            'items_analyzed': len(posts),
            'report_title': title,
            'report_content': report_content,
        }
        report_id = self.db.save_report(report_row)

        result = {
            'success': True,
            'report_id': report_id,
            'items_analyzed': len(posts),
            'title': title,
        }

        # å°è¯•æ¨é€åˆ°Notion
        try:
            from .notion_client import jike_notion_client

            # æ ¼å¼åŒ–Notionæ ‡é¢˜
            beijing_time = self._bj_time()
            time_str = beijing_time.strftime('%H:%M')
            notion_title = f"[{time_str}] å³åˆ»24hçƒ­ç‚¹è§‚å¯Ÿ ({len(posts)}æ¡åŠ¨æ€)"

            self.logger.info(f"å¼€å§‹æ¨é€æ—¥æŠ¥åˆ°Notion: {notion_title}")

            notion_result = jike_notion_client.create_report_page(
                report_title=notion_title,
                report_content=report_content,
                report_date=beijing_time
            )

            if notion_result.get('success'):
                self.logger.info(f"æ—¥æŠ¥æˆåŠŸæ¨é€åˆ°Notion: {notion_result.get('page_url')}")
                result['notion_push'] = {
                    'success': True,
                    'page_url': notion_result.get('page_url'),
                    'path': notion_result.get('path')
                }
            else:
                self.logger.warning(f"æ¨é€æ—¥æŠ¥åˆ°Notionå¤±è´¥: {notion_result.get('error')}")
                result['notion_push'] = {
                    'success': False,
                    'error': notion_result.get('error')
                }

        except Exception as e:
            self.logger.warning(f"æ¨é€æ—¥æŠ¥åˆ°Notionæ—¶å‡ºé”™: {e}")
            result['notion_push'] = {
                'success': False,
                'error': str(e)
            }

        return result

    def generate_weekly_digest(self, days_back: Optional[int] = None) -> Dict[str, Any]:
        days = int(days_back or self.analysis_cfg.get('days_back_weekly', 7))
        end_time = self._bj_time()
        start_time = end_time - timedelta(days=days)

        posts = self.db.get_posts_for_analysis(days=days)
        if not posts:
            return {'success': False, 'error': f'æœ€è¿‘{days}å¤©å†…æ— åŠ¨æ€å¯åˆ†æ'}

        content_md, sources = self._format_posts_for_llm(posts, source_prefix='T')
        llm_analysis_result = self._analyze_with_llm(content_md, self._prompt_weekly())
        if not llm_analysis_result:
            header = "# å³åˆ»å‘¨åº¦ç¤¾ç¾¤æ´å¯Ÿ (å ä½ç‰ˆ)"
            report_content = self._make_fallback_report(header, posts, start_time, end_time, sources)
        else:
            llm_output = llm_analysis_result.get('content', '')
            # ä¸ºLLMç”Ÿæˆçš„æŠ¥å‘Šæ·»åŠ æ ‡å‡†å¤´éƒ¨ä¿¡æ¯
            beijing_time = self._bj_time()
            header_info = [
                f"# ğŸ“Š å³åˆ»å‘¨åº¦ç¤¾ç¾¤æ´å¯Ÿ",
                "",
                f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {beijing_time.strftime('%Y-%m-%d %H:%M:%S')}*  ",
                "",
                f"*æ•°æ®èŒƒå›´: {start_time.strftime('%Y-%m-%d %H:%M:%S')} - {end_time.strftime('%Y-%m-%d %H:%M:%S')}*  ",
                "",
                f"*åˆ†æåŠ¨æ€æ•°: {len(posts)} æ¡*",
                "",
                "---",
                ""
            ]

            # æ¸…ç†LLMè¾“å‡ºä¸­å¯èƒ½çš„æ ¼å¼é—®é¢˜
            cleaned_llm_output = self._clean_llm_output_for_notion(llm_output)

            sources_section = self._render_sources_section(sources)

            # æ„å»ºæŠ¥å‘Šå°¾éƒ¨
            footer_lines = ["", "---", ""]
            provider = llm_analysis_result.get('provider')
            model = llm_analysis_result.get('model')
            if provider:
                footer_lines.append(f"*åˆ†æå¼•æ“: {provider} ({model or 'unknown'})*")
            
            footer_lines.extend([
                "",
                "*æœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒ*"
            ])
            footer_section = "\n".join(footer_lines)

            report_content = "\n".join(header_info) + cleaned_llm_output + "\n\n" + sources_section + footer_section

        title = f"å³åˆ»å‘¨åº¦ç¤¾ç¾¤æ´å¯Ÿ - æˆªæ­¢ {end_time.strftime('%Y-%m-%d')}"
        report_row = {
            'report_type': 'weekly_digest',
            'scope': 'global',
            'analysis_period_start': start_time,
            'analysis_period_end': end_time,
            'items_analyzed': len(posts),
            'report_title': title,
            'report_content': report_content,
        }
        report_id = self.db.save_report(report_row)

        result = {
            'success': True,
            'report_id': report_id,
            'items_analyzed': len(posts),
            'title': title,
        }

        # å°è¯•æ¨é€åˆ°Notion
        try:
            from .notion_client import jike_notion_client

            # æ ¼å¼åŒ–Notionæ ‡é¢˜
            beijing_time = self._bj_time()
            notion_title = f"å³åˆ»å‘¨åº¦ç¤¾ç¾¤æ´å¯Ÿ - {beijing_time.strftime('%Y%m%d')} ({len(posts)}æ¡åŠ¨æ€)"

            self.logger.info(f"å¼€å§‹æ¨é€å‘¨æŠ¥åˆ°Notion: {notion_title}")

            notion_result = jike_notion_client.create_report_page(
                report_title=notion_title,
                report_content=report_content,
                report_date=beijing_time
            )

            if notion_result.get('success'):
                self.logger.info(f"å‘¨æŠ¥æˆåŠŸæ¨é€åˆ°Notion: {notion_result.get('page_url')}")
                result['notion_push'] = {
                    'success': True,
                    'page_url': notion_result.get('page_url'),
                    'path': notion_result.get('path')
                }
            else:
                self.logger.warning(f"æ¨é€å‘¨æŠ¥åˆ°Notionå¤±è´¥: {notion_result.get('error')}")
                result['notion_push'] = {
                    'success': False,
                    'error': notion_result.get('error')
                }

        except Exception as e:
            self.logger.warning(f"æ¨é€å‘¨æŠ¥åˆ°Notionæ—¶å‡ºé”™: {e}")
            result['notion_push'] = {
                'success': False,
                'error': str(e)
            }

        return result

    def generate_quarterly_narrative(self, days_back: Optional[int] = None) -> Dict[str, Any]:
        days = int(days_back or self.analysis_cfg.get('days_back_quarterly', 90))
        end_time = self._bj_time()
        start_time = end_time - timedelta(days=days)

        posts = self.db.get_posts_for_analysis(days=days)
        if not posts:
            return {'success': False, 'error': f'æœ€è¿‘{days}å¤©å†…æ— åŠ¨æ€å¯åˆ†æ'}

        # å¤ç”¨å‘¨æŠ¥æç¤ºè¯ï¼Œå®é™…å¯æ›´å¤æ‚
        content_md, sources = self._format_posts_for_llm(posts, source_prefix='T')
        llm_analysis_result = self._analyze_with_llm(content_md, self._prompt_weekly())
        if not llm_analysis_result:
            header = "# å³åˆ»å­£åº¦æˆ˜ç•¥å™äº‹ (å ä½ç‰ˆ)"
            report_content = self._make_fallback_report(header, posts, start_time, end_time, sources)
        else:
            llm_output = llm_analysis_result.get('content', '')
            # ä¸ºLLMç”Ÿæˆçš„æŠ¥å‘Šæ·»åŠ æ ‡å‡†å¤´éƒ¨ä¿¡æ¯
            beijing_time = self._bj_time()
            q = (end_time.month - 1) // 3 + 1
            header_info = [
                f"# ğŸš€ å³åˆ»å­£åº¦æˆ˜ç•¥å™äº‹ - {end_time.year} Q{q}",
                "",
                f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {beijing_time.strftime('%Y-%m-%d %H:%M:%S')}*  ",
                "",
                f"*æ•°æ®èŒƒå›´: {start_time.strftime('%Y-%m-%d %H:%M:%S')} - {end_time.strftime('%Y-%m-%d %H:%M:%S')}*  ",
                "",
                f"*åˆ†æåŠ¨æ€æ•°: {len(posts)} æ¡*",
                "",
                "---",
                ""
            ]

            # æ¸…ç†LLMè¾“å‡ºä¸­å¯èƒ½çš„æ ¼å¼é—®é¢˜
            cleaned_llm_output = self._clean_llm_output_for_notion(llm_output)

            sources_section = self._render_sources_section(sources)

            # æ„å»ºæŠ¥å‘Šå°¾éƒ¨
            footer_lines = ["", "---", ""]
            provider = llm_analysis_result.get('provider')
            model = llm_analysis_result.get('model')
            if provider:
                footer_lines.append(f"*åˆ†æå¼•æ“: {provider} ({model or 'unknown'})*")
            
            footer_lines.extend([
                "",
                "*æœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒ*"
            ])
            footer_section = "\n".join(footer_lines)

            report_content = "\n".join(header_info) + cleaned_llm_output + "\n\n" + sources_section + footer_section

        # ç®€å•å­£åº¦æ ‡é¢˜
        q = (end_time.month - 1) // 3 + 1
        title = f"å³åˆ»å­£åº¦æˆ˜ç•¥å™äº‹ - {end_time.year} Q{q}"
        report_row = {
            'report_type': 'quarterly_narrative',
            'scope': 'global',
            'analysis_period_start': start_time,
            'analysis_period_end': end_time,
            'items_analyzed': len(posts),
            'report_title': title,
            'report_content': report_content,
        }
        report_id = self.db.save_report(report_row)

        result = {
            'success': True,
            'report_id': report_id,
            'items_analyzed': len(posts),
            'title': title,
        }

        # å°è¯•æ¨é€åˆ°Notion
        try:
            from .notion_client import jike_notion_client

            # æ ¼å¼åŒ–Notionæ ‡é¢˜
            beijing_time = self._bj_time()
            notion_title = f"å³åˆ»å­£åº¦æˆ˜ç•¥å™äº‹ - {end_time.year}Q{q} ({len(posts)}æ¡åŠ¨æ€)"

            self.logger.info(f"å¼€å§‹æ¨é€å­£æŠ¥åˆ°Notion: {notion_title}")

            notion_result = jike_notion_client.create_report_page(
                report_title=notion_title,
                report_content=report_content,
                report_date=beijing_time
            )

            if notion_result.get('success'):
                self.logger.info(f"å­£æŠ¥æˆåŠŸæ¨é€åˆ°Notion: {notion_result.get('page_url')}")
                result['notion_push'] = {
                    'success': True,
                    'page_url': notion_result.get('page_url'),
                    'path': notion_result.get('path')
                }
            else:
                self.logger.warning(f"æ¨é€å­£æŠ¥åˆ°Notionå¤±è´¥: {notion_result.get('error')}")
                result['notion_push'] = {
                    'success': False,
                    'error': notion_result.get('error')
                }

        except Exception as e:
            self.logger.warning(f"æ¨é€å­£æŠ¥åˆ°Notionæ—¶å‡ºé”™: {e}")
            result['notion_push'] = {
                'success': False,
                'error': str(e)
            }

        return result

    def generate_kol_trajectory(self, kol_ids: Optional[List[str]] = None, days_back: Optional[int] = None) -> Dict[str, Any]:
        """ä¸ºå¤šä¸ªKOLç”ŸæˆæŒ‰äººç»´åº¦çš„æ€æƒ³è½¨è¿¹å›¾ï¼ˆå¹¶å‘å¤„ç†ï¼‰ã€‚è¿”å›ç»Ÿè®¡ç»“æœã€‚"""
        ids = kol_ids or self.analysis_cfg.get('kol_user_ids') or []
        days = int(days_back or self.analysis_cfg.get('days_back_kol', 30))
        if not ids:
            return {'success': False, 'error': 'æœªæä¾›KOLç”¨æˆ·IDåˆ—è¡¨'}

        end_time_global = self._bj_time()
        start_time_global = end_time_global - timedelta(days=days)

        generated, failed = 0, 0

        def _do_one(uid: str) -> bool:
            nonlocal start_time_global, end_time_global
            posts = self.db.get_user_posts_for_analysis(jike_user_id=uid, days=days)
            if not posts:
                self.logger.info(f"KOLæ— ç´ æï¼Œè·³è¿‡: {uid}")
                return False
            content_md, sources = self._format_posts_for_llm(posts, source_prefix='T')
            # æš‚å¤ç”¨å‘¨æŠ¥æç¤ºè¯
            llm_analysis_result = self._analyze_with_llm(content_md, self._prompt_weekly())
            if not llm_analysis_result:
                header = f"# å³åˆ»KOLæ€æƒ³è½¨è¿¹ (å ä½ç‰ˆ) - {uid}"
                report_content = self._make_fallback_report(header, posts, start_time_global, end_time_global, sources)
            else:
                llm_output = llm_analysis_result.get('content', '')
                # ä¸ºLLMç”Ÿæˆçš„æŠ¥å‘Šæ·»åŠ æ ‡å‡†å¤´éƒ¨ä¿¡æ¯
                beijing_time = self._bj_time()
                header_info = [
                    f"# ğŸ¯ å³åˆ»KOLæ€æƒ³è½¨è¿¹ - {uid}",
                    "",
                    f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {beijing_time.strftime('%Y-%m-%d %H:%M:%S')}*  ",
                    "",
                    f"*æ•°æ®èŒƒå›´: {start_time_global.strftime('%Y-%m-%d %H:%M:%S')} - {end_time_global.strftime('%Y-%m-%d %H:%M:%S')}*  ",
                    "",
                    f"*åˆ†æåŠ¨æ€æ•°: {len(posts)} æ¡*",
                    "",
                    "---",
                    ""
                ]

                # æ¸…ç†LLMè¾“å‡ºä¸­å¯èƒ½çš„æ ¼å¼é—®é¢˜
                cleaned_llm_output = self._clean_llm_output_for_notion(llm_output)

                sources_section = self._render_sources_section(sources)

                # æ„å»ºæŠ¥å‘Šå°¾éƒ¨
                footer_lines = ["", "---", ""]
                provider = llm_analysis_result.get('provider')
                model = llm_analysis_result.get('model')
                if provider:
                    footer_lines.append(f"*åˆ†æå¼•æ“: {provider} ({model or 'unknown'})*")
                
                footer_lines.extend([
                    "",
                    "*æœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒ*"
                ])
                footer_section = "\n".join(footer_lines)

                report_content = "\n".join(header_info) + cleaned_llm_output + "\n\n" + sources_section + footer_section

            title = f"KOLæ€æƒ³è½¨è¿¹ - {uid} - æˆªæ­¢ {end_time_global.strftime('%Y-%m-%d')}"
            row = {
                'report_type': 'kol_trajectory',
                'scope': f'kol:{uid}',
                'analysis_period_start': start_time_global,
                'analysis_period_end': end_time_global,
                'items_analyzed': len(posts),
                'report_title': title,
                'report_content': report_content,
            }
            report_id = self.db.save_report(row)

            # å°è¯•æ¨é€KOLæŠ¥å‘Šåˆ°Notion
            try:
                from .notion_client import jike_notion_client

                # æ ¼å¼åŒ–Notionæ ‡é¢˜
                beijing_time = self._bj_time()
                notion_title = f"KOLæ€æƒ³è½¨è¿¹ - {uid} - {beijing_time.strftime('%Y%m%d')} ({len(posts)}æ¡åŠ¨æ€)"

                self.logger.info(f"å¼€å§‹æ¨é€KOLæŠ¥å‘Šåˆ°Notion: {notion_title}")

                notion_result = jike_notion_client.create_report_page(
                    report_title=notion_title,
                    report_content=report_content,
                    report_date=beijing_time
                )

                if notion_result.get('success'):
                    self.logger.info(f"KOLæŠ¥å‘ŠæˆåŠŸæ¨é€åˆ°Notion: {notion_result.get('page_url')}")
                else:
                    self.logger.warning(f"æ¨é€KOLæŠ¥å‘Šåˆ°Notionå¤±è´¥: {notion_result.get('error')}")

            except Exception as e:
                self.logger.warning(f"æ¨é€KOLæŠ¥å‘Šåˆ°Notionæ—¶å‡ºé”™: {e}")

            return True

        with ThreadPoolExecutor(max_workers=self.max_llm_concurrency) as ex:
            futures = {ex.submit(_do_one, uid): uid for uid in ids}
            for f in as_completed(futures):
                ok = False
                try:
                    ok = bool(f.result())
                except Exception as e:
                    self.logger.warning(f"ç”ŸæˆKOLæŠ¥å‘Šå¤±è´¥: {futures[f]} - {e}")
                    ok = False
                generated += 1 if ok else 0
                failed += 0 if ok else 1

        return {'success': True, 'generated': generated, 'failed': failed}


def get_report_generator() -> JKReportGenerator:
    """æ¨¡å—çº§å·¥å‚å‡½æ•°ï¼Œä¾›taskså»¶è¿Ÿå¯¼å…¥è°ƒç”¨"""
    return JKReportGenerator()
