"""
å³åˆ»åˆ†ææŠ¥å‘Šç”Ÿæˆå™¨
å®ç°å››ç±»æŠ¥å‘Šï¼š
- daily_hotspot: 24å°æ—¶çƒ­ç‚¹è¿½è¸ªå™¨
- weekly_digest: å‘¨åº¦ç¤¾ç¾¤æ´å¯Ÿæ‘˜è¦
- kol_trajectory: æœˆåº¦KOLæ€æƒ³è½¨è¿¹å›¾ï¼ˆå¯å¹¶å‘å¤šç”¨æˆ·ï¼‰
- quarterly_narrative: å­£åº¦æˆ˜ç•¥å™äº‹åˆ†æ

è¾“å‡ºä¿å­˜è‡³ jk_reports è¡¨,å¹¶åœ¨æŠ¥å‘Šä¸­é™„å¸¦æ¥æºæ¸…å•ã€‚
"""
from __future__ import annotations

import logging
import asyncio
from typing import Any, Dict, List, Optional, Tuple
from datetime import datetime, timezone, timedelta

try:
    from .database import DatabaseManager
    from .config import config
    from .llm_client import llm_client
except ImportError:  # pragma: no cover
    from database import DatabaseManager  # type: ignore
    from config import config  # type: ignore
    from llm_client import llm_client  # type: ignore


class JKReportGenerator:
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.db = DatabaseManager(config)
        self.llm_cfg = config.get_llm_config()
        self.analysis_cfg = config.get_analysis_config()
        self.max_content_length = int(self.llm_cfg.get('max_content_length', 380000))
        self.max_llm_concurrency = 3  # ä¸linuxdoä¿æŒä¸€è‡´,ä¸ä»[llm]è¯»å–

        # è·å–æŠ¥å‘Šä¸Šä¸‹æ–‡æ¨¡å¼é…ç½®ï¼ˆä¸post_processorçš„interpretation_modeç‹¬ç«‹ï¼‰
        context_mode = (self.analysis_cfg.get('report_context_mode') if self.analysis_cfg else 'light') or 'light'
        if not isinstance(context_mode, str):
            context_mode = 'light'
        context_mode = context_mode.lower()
        if context_mode not in {'light', 'full'}:
            self.logger.warning(f"æœªçŸ¥report_context_modeé…ç½®: {context_mode}, å›é€€åˆ°lightæ¨¡å¼")
            context_mode = 'light'
        self.context_mode = context_mode

        self.logger.info(f"æŠ¥å‘Šç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆï¼Œreport_context_mode={self.context_mode}")

    def _log_task_start(self, task_type: str, **kwargs) -> None:
        """ç»Ÿä¸€çš„ä»»åŠ¡å¼€å§‹æ—¥å¿—è®°å½•"""
        details = ", ".join([f"{k}={v}" for k, v in kwargs.items()])
        self.logger.info(f"å¼€å§‹æ‰§è¡Œ {task_type} ä»»åŠ¡: {details}")

    def _log_task_complete(self, task_type: str, success_count: int, failure_count: int, **kwargs) -> None:
        """ç»Ÿä¸€çš„ä»»åŠ¡å®Œæˆæ—¥å¿—è®°å½•"""
        status = "æˆåŠŸ" if failure_count == 0 else f"éƒ¨åˆ†æˆåŠŸ"
        details = ", ".join([f"{k}={v}" for k, v in kwargs.items()])
        self.logger.info(f"{task_type} ä»»åŠ¡å®Œæˆ ({status}): æˆåŠŸ {success_count} ä¸ªï¼Œå¤±è´¥ {failure_count} ä¸ªã€‚{details}")

    def _handle_task_exception(self, task_type: str, model_name: str, display_name: str, exception: Exception) -> Dict[str, Any]:
        """ç»Ÿä¸€çš„ä»»åŠ¡å¼‚å¸¸å¤„ç†"""
        error_msg = str(exception)
        self.logger.warning(f"{task_type} ä»»åŠ¡å¼‚å¸¸ - æ¨¡å‹ {model_name} ({display_name}): {error_msg}")
        return {
            'model': model_name,
            'model_display': display_name,
            'success': False,
            'error': error_msg,
            'error_type': type(exception).__name__
        }

    def _create_error_response(self, error_msg: str, **additional_fields) -> Dict[str, Any]:
        """åˆ›å»ºæ ‡å‡†åŒ–çš„é”™è¯¯å“åº”"""
        response = {
            'success': False,
            'error': error_msg,
            'items_analyzed': 0
        }
        response.update(additional_fields)
        return response

    def _bj_time(self) -> datetime:
        return datetime.now(timezone.utc) + timedelta(hours=8)

    def _get_report_models(self) -> List[str]:
        """è·å–ç”¨äºç”ŸæˆæŠ¥å‘Šçš„æ¨¡å‹åˆ—è¡¨ï¼ˆä¼˜å…ˆæ¨¡å‹ + é»˜è®¤æ¨¡å‹ï¼‰"""
        if not llm_client:
            return []

        models: List[str] = []
        raw_models = getattr(llm_client, 'models', None) or []

        for model_name in raw_models:
            if model_name and model_name not in models:
                models.append(model_name)

        if models:
            return models

        base_model = getattr(llm_client, 'smart_model', None)
        priority_model = getattr(llm_client, 'priority_model', None)

        if base_model:
            models.append(base_model)
        if priority_model and priority_model not in models:
            models.insert(0, priority_model)

        return models

    def _get_model_display_name(self, model_name: str) -> str:
        """æ ¹æ®æ¨¡å‹åç§°ç”Ÿæˆç”¨äºå±•ç¤ºçš„å‹å¥½åç§°"""
        if not model_name:
            return 'LLM'

        lower_name = model_name.lower()
        if 'gemini' in lower_name:
            return 'Gemini'
        if 'deepseek' in lower_name:
            return 'DeepSeek'
        if 'grok' in lower_name:
            return 'Grok'
        # GLMæ¨¡å‹è¯†åˆ«ï¼šé€šç”¨æå–ç‰ˆæœ¬å·ï¼ˆå¦‚GLM-4.5ã€GLM-4.6ã€GLM-4vç­‰ï¼‰
        if 'glm' in lower_name:
            import re
            # åŒ¹é… GLM-æ•°å­—.æ•°å­— æˆ– GLM-æ•°å­—v ç­‰æ ¼å¼
            match = re.search(r'glm[- ]?(\d+\.?\d*v?)', lower_name)
            if match:
                version = match.group(1)
                return f'GLM{version}'
            else:
                return 'GLM'
        if 'gpt' in lower_name:
            return 'GPT'
        if 'claude' in lower_name:
            return 'Claude'

        return model_name

    async def _generate_daily_report_for_model(
        self,
        *,
        model_name: str,
        display_name: str,
        posts: List[Dict[str, Any]],
        content_md: str,
        sources: List[Dict[str, Any]],
        prompt: str,
        start_time: datetime,
        end_time: datetime
    ) -> Dict[str, Any]:
        """åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­ç”ŸæˆæŒ‡å®šæ¨¡å‹çš„æ—¥æŠ¥"""
        return await asyncio.to_thread(
            self._generate_daily_report_for_model_sync,
            model_name,
            display_name,
            posts,
            content_md,
            sources,
            prompt,
            start_time,
            end_time
        )

    def _generate_daily_report_for_model_sync(
        self,
        model_name: str,
        display_name: str,
        posts: List[Dict[str, Any]],
        content_md: str,
        sources: List[Dict[str, Any]],
        prompt: str,
        start_time: datetime,
        end_time: datetime
    ) -> Dict[str, Any]:
        """åŒæ­¥æ‰§è¡ŒæŒ‡å®šæ¨¡å‹çš„æ—¥æŠ¥ç”Ÿæˆå’ŒNotionæ¨é€"""

        self.logger.info(f"[{display_name}] æ¨¡å‹çº¿ç¨‹å¯åŠ¨ï¼Œå¼€å§‹ç”Ÿæˆæ—¥æŠ¥")

        llm_analysis_result = self._analyze_with_llm(content_md, prompt, model_override=model_name)

        if not llm_analysis_result:
            error_msg = "LLMåˆ†æå¤±è´¥ï¼Œæœªç”Ÿæˆæ—¥æŠ¥"
            self.logger.warning(f"[{display_name}] {error_msg}")
            return {
                'success': False,
                'error': error_msg,
                'model': model_name,
                'model_display': display_name
            }

        llm_output = llm_analysis_result.get('content', '')
        # ä¸ºLLMç”Ÿæˆçš„æŠ¥å‘Šæ·»åŠ æ ‡å‡†å¤´éƒ¨ä¿¡æ¯
        beijing_time = self._bj_time()
        header_info = [
            f"# ğŸ“ˆ å³åˆ»24å°æ—¶çƒ­ç‚¹è¿½è¸ªå™¨ - {display_name}",
            "",
            f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {beijing_time.strftime('%Y-%m-%d %H:%M:%S')}*  ",
            "",
            f"*æ•°æ®èŒƒå›´: {start_time.strftime('%Y-%m-%d %H:%M:%S')} - {end_time.strftime('%Y-%m-%d %H:%M:%S')}*  ",
            "",
            f"*åˆ†æåŠ¨æ€æ•°: {len(posts)} æ¡*",
            "",
            "---",
            ""
        ]

        # æ¸…ç†LLMè¾“å‡ºä¸­å¯èƒ½çš„æ ¼å¼é—®é¢˜
        cleaned_llm_output = self._clean_llm_output_for_notion(llm_output)

        sources_section = self._render_sources_section(sources)

        # æ„å»ºæŠ¥å‘Šå°¾éƒ¨
        footer_lines = ["", "---", ""]
        provider = llm_analysis_result.get('provider')
        model = llm_analysis_result.get('model')
        if provider:
            footer_lines.append(f"*åˆ†æå¼•æ“: {provider} ({model or 'unknown'})*")
        
        footer_lines.extend([
            "",
            f"ğŸ“Š **ç»Ÿè®¡æ‘˜è¦**: æœ¬æŠ¥å‘Šåˆ†æäº† {len(posts)} æ¡åŠ¨æ€",
            "",
            "*æœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒ*"
        ])
        footer_section = "\n".join(footer_lines)

        report_content = "\n".join(header_info) + cleaned_llm_output + "\n\n" + sources_section + footer_section

        # åº”ç”¨æ¥æºé“¾æ¥å¢å¼ºåå¤„ç†
        report_content = self._enhance_source_links(report_content, sources)

        title = f"å³åˆ»24hçƒ­ç‚¹è§‚å¯Ÿ - {display_name} - {end_time.strftime('%Y-%m-%d %H:%M')}"
        report_row = {
            'report_type': 'daily_hotspot',
            'scope': 'global',
            'analysis_period_start': start_time,
            'analysis_period_end': end_time,
            'items_analyzed': len(posts),
            'report_title': title,
            'report_content': report_content,
        }
        report_id = self.db.save_report(report_row)

        model_report = {
            'model': model_name,
            'model_display': display_name,
            'success': True,
            'report_id': report_id,
            'report_title': title,
            'provider': llm_analysis_result.get('provider') if llm_analysis_result else None,
            'items_analyzed': len(posts)
        }

        # å°è¯•æ¨é€åˆ°Notion
        notion_push_info = None
        try:
            from .notion_client import jike_notion_client

            # æ ¼å¼åŒ–Notionæ ‡é¢˜
            beijing_time = self._bj_time()
            time_str = beijing_time.strftime('%H:%M')
            notion_title = f"[{time_str}] [{display_name}] å³åˆ»24hçƒ­ç‚¹è§‚å¯Ÿ ({len(posts)}æ¡åŠ¨æ€)"

            self.logger.info(f"å¼€å§‹æ¨é€æ—¥æŠ¥åˆ°Notion ({display_name}): {notion_title}")

            notion_result = jike_notion_client.create_report_page(
                report_title=notion_title,
                report_content=report_content,
                report_date=beijing_time
            )

            if notion_result.get('success'):
                self.logger.info(f"æ—¥æŠ¥æˆåŠŸæ¨é€åˆ°Notion ({display_name}): {notion_result.get('page_url')}")
                notion_push_info = {
                    'success': True,
                    'page_url': notion_result.get('page_url'),
                    'path': notion_result.get('path')
                }
            else:
                error_msg = notion_result.get('error', 'æœªçŸ¥é”™è¯¯')
                self.logger.warning(f"æ¨é€æ—¥æŠ¥åˆ°Notionå¤±è´¥ ({display_name}): {error_msg}")
                notion_push_info = {
                    'success': False,
                    'error': error_msg
                }

        except Exception as e:
            self.logger.warning(f"æ¨é€æ—¥æŠ¥åˆ°Notionæ—¶å‡ºé”™ ({display_name}): {e}")
            notion_push_info = {
                'success': False,
                'error': str(e)
            }

        if notion_push_info:
            model_report['notion_push'] = notion_push_info

        return model_report

    async def _generate_weekly_report_for_model(
        self,
        *,
        model_name: str,
        display_name: str,
        daily_reports: List[Dict[str, Any]],
        content_md: str,
        sources: List[Dict[str, Any]],
        start_time: datetime,
        end_time: datetime,
        items_analyzed: int
    ) -> Dict[str, Any]:
        """åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­ç”ŸæˆæŒ‡å®šæ¨¡å‹çš„å‘¨æŠ¥"""
        return await asyncio.to_thread(
            self._generate_weekly_report_for_model_sync,
            model_name,
            display_name,
            daily_reports,
            content_md,
            sources,
            start_time,
            end_time,
            items_analyzed
        )

    def _generate_weekly_report_for_model_sync(
        self,
        model_name: str,
        display_name: str,
        daily_reports: List[Dict[str, Any]],
        content_md: str,
        sources: List[Dict[str, Any]],
        start_time: datetime,
        end_time: datetime,
        items_analyzed: int
    ) -> Dict[str, Any]:
        """åŒæ­¥æ‰§è¡ŒæŒ‡å®šæ¨¡å‹çš„å‘¨æŠ¥ç”Ÿæˆå’ŒNotionæ¨é€"""

        self.logger.info(f"[{display_name}] æ¨¡å‹çº¿ç¨‹å¯åŠ¨ï¼Œå¼€å§‹ç”Ÿæˆå‘¨æŠ¥")

        llm_analysis_result = self._analyze_with_llm(content_md, self._prompt_weekly(), model_override=model_name)

        if not llm_analysis_result:
            error_msg = "LLMåˆ†æå¤±è´¥ï¼Œæœªç”Ÿæˆå‘¨æŠ¥"
            self.logger.warning(f"[{display_name}] {error_msg}")
            return {
                'success': False,
                'error': error_msg,
                'model': model_name,
                'model_display': display_name
            }

        llm_output = llm_analysis_result.get('content', '')
        beijing_time = self._bj_time()
        header_info = [
            f"# ğŸ“Š å³åˆ»å‘¨åº¦ç¤¾ç¾¤æ´å¯Ÿ - {display_name}",
            "",
            f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {beijing_time.strftime('%Y-%m-%d %H:%M:%S')}*  ",
            "",
            f"*è¦†ç›–åŒºé—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')} - {end_time.strftime('%Y-%m-%d %H:%M:%S')}*  ",
            "",
            f"*æ—¥æŠ¥æ¥æºæ•°: {len(daily_reports)} ç¯‡ | è¦†ç›–åŠ¨æ€ {items_analyzed} æ¡*",
            "",
            "---",
            ""
        ]

        cleaned_llm_output = self._clean_llm_output_for_notion(llm_output)
        sources_section = self._render_sources_section(sources)

        footer_lines = ["", "---", ""]
        provider = llm_analysis_result.get('provider')
        model = llm_analysis_result.get('model')
        if provider:
            footer_lines.append(f"*åˆ†æå¼•æ“: {provider} ({model or 'unknown'})*")
        
        footer_lines.extend([
            "",
            "*æœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒ*"
        ])
        footer_section = "\n".join(footer_lines)

        report_parts: List[str] = ["\n".join(header_info), cleaned_llm_output]
        if sources_section:
            report_parts.append("")
            report_parts.append(sources_section)
        report_parts.append("")
        report_parts.append(footer_section)

        report_content = "\n".join(report_parts)
        report_content = self._enhance_source_links(report_content, sources)

        title = f"å³åˆ»å‘¨åº¦ç¤¾ç¾¤æ´å¯Ÿ - {display_name} - æˆªæ­¢ {end_time.strftime('%Y-%m-%d')}"
        report_row = {
            'report_type': 'weekly_digest',
            'scope': 'global',
            'analysis_period_start': start_time,
            'analysis_period_end': end_time,
            'items_analyzed': items_analyzed,
            'report_title': title,
            'report_content': report_content,
        }
        report_id = self.db.save_report(report_row)

        model_report = {
            'model': model_name,
            'model_display': display_name,
            'success': True,
            'report_id': report_id,
            'report_title': title,
            'provider': llm_analysis_result.get('provider') if llm_analysis_result else None,
            'items_analyzed': items_analyzed
        }

        # å°è¯•æ¨é€åˆ°Notion
        notion_push_info = None
        try:
            from .notion_client import jike_notion_client

            # æ ¼å¼åŒ–Notionæ ‡é¢˜
            beijing_time = self._bj_time()
            notion_title = f"[{display_name}] å³åˆ»å‘¨åº¦ç¤¾ç¾¤æ´å¯Ÿ - {beijing_time.strftime('%Y%m%d')} ({items_analyzed}æ¡åŠ¨æ€)"

            self.logger.info(f"å¼€å§‹æ¨é€å‘¨æŠ¥åˆ°Notion ({display_name}): {notion_title}")

            notion_result = jike_notion_client.create_report_page(
                report_title=notion_title,
                report_content=report_content,
                report_date=beijing_time
            )

            if notion_result.get('success'):
                self.logger.info(f"å‘¨æŠ¥æˆåŠŸæ¨é€åˆ°Notion ({display_name}): {notion_result.get('page_url')}")
                notion_push_info = {
                    'success': True,
                    'page_url': notion_result.get('page_url'),
                    'path': notion_result.get('path')
                }
            else:
                error_msg = notion_result.get('error', 'æœªçŸ¥é”™è¯¯')
                self.logger.warning(f"æ¨é€å‘¨æŠ¥åˆ°Notionå¤±è´¥ ({display_name}): {error_msg}")
                notion_push_info = {
                    'success': False,
                    'error': error_msg
                }

        except Exception as e:
            self.logger.warning(f"æ¨é€å‘¨æŠ¥åˆ°Notionæ—¶å‡ºé”™ ({display_name}): {e}")
            notion_push_info = {
                'success': False,
                'error': str(e)
            }

        if notion_push_info:
            model_report['notion_push'] = notion_push_info

        return model_report

    # ---------- æ•°æ®å‡†å¤‡ä¸æ ¼å¼åŒ– ----------
    def _post_has_media(self, post: Dict[str, Any]) -> bool:
        """åˆ¤æ–­å¸–å­æ˜¯å¦åŒ…å«åª’ä½“å†…å®¹ï¼ˆå›¾ç‰‡ï¼‰"""
        import re

        # è·å–å¸–å­å†…å®¹
        post_text = post.get('summary', '') or post.get('title', '')
        if not post_text:
            return False

        # æ£€æŸ¥æ˜¯å¦åŒ…å« Markdown å›¾ç‰‡è¯­æ³•
        img_pattern = r'!\[.*?\]\((https?://[^)]+)\)'
        image_urls = re.findall(img_pattern, post_text)

        return len(image_urls) > 0

    def _get_media_count(self, post: Dict[str, Any]) -> int:
        """è·å–å¸–å­ä¸­çš„å›¾ç‰‡æ•°é‡"""
        import re

        post_text = post.get('summary', '') or post.get('title', '')
        if not post_text:
            return 0

        img_pattern = r'!\[.*?\]\((https?://[^)]+)\)'
        image_urls = re.findall(img_pattern, post_text)

        return len(image_urls)

    def _clean_image_urls_from_content(self, content: str, media_count: int = 0) -> str:
        """
        æ¸…ç†å¸–å­å†…å®¹ä¸­çš„å›¾ç‰‡URLï¼Œæ›¿æ¢ä¸ºç®€çŸ­è¯´æ˜

        Args:
            content: åŸå§‹å¸–å­å†…å®¹
            media_count: å›¾ç‰‡æ•°é‡

        Returns:
            æ¸…ç†åçš„å†…å®¹
        """
        if not content:
            return ""

        import re

        # åŒ¹é…markdownå›¾ç‰‡è¯­æ³•ï¼š![...](...) æˆ– ![](...)
        # ä»¥åŠå„ç§å›¾ç‰‡URLæ¨¡å¼
        markdown_img_pattern = r'!\[.*?\]\([^\)]+\)'

        # ç§»é™¤æ‰€æœ‰markdownå›¾ç‰‡
        cleaned = re.sub(markdown_img_pattern, '', content)

        # ç§»é™¤å¯èƒ½çš„å›¾ç‰‡URLï¼ˆå¸¸è§çš„å›¾ç‰‡åŸŸåï¼‰
        img_url_patterns = [
            r'https?://[^\s]*\.(?:jpg|jpeg|png|gif|webp|bmp)[^\s]*',
            r'https?://img\.[^\s]+',
            r'https?://image\.[^\s]+',
            r'https?://pic\.[^\s]+',
        ]

        for pattern in img_url_patterns:
            cleaned = re.sub(pattern, '', cleaned, flags=re.IGNORECASE)

        # æ¸…ç†å¤šä½™çš„ç©ºè¡Œï¼ˆä¿ç•™æœ€å¤šä¸€ä¸ªç©ºè¡Œï¼‰
        cleaned = re.sub(r'\n{3,}', '\n\n', cleaned)
        cleaned = cleaned.strip()

        # åœ¨å†…å®¹å¼€å¤´æ·»åŠ ç®€çŸ­çš„å›¾ç‰‡è¯´æ˜
        if media_count > 0:
            img_note = f"[é™„{media_count}å¼ å›¾]"
            cleaned = f"{img_note}\n{cleaned}"

        return cleaned

    def _truncate(self, text: str, max_len: int) -> str:
        if not text:
            return ""
        if len(text) <= max_len:
            return text
        t = text[:max_len]
        # å°è¯•åœ¨å¥å°¾æˆªæ–­
        for d in ['ã€‚', '!', '?', '.', '!', '?', '\n']:
            pos = t.rfind(d)
            if pos > max_len * 0.7:
                return t[:pos + 1] + "\n..."
        return t + "\n..."

    def _clean_llm_output_for_notion(self, llm_output: str) -> str:
        """æ¸…ç†LLMè¾“å‡ºå†…å®¹ï¼Œç¡®ä¿Notionå…¼å®¹æ€§"""
        if not llm_output:
            return ""

        # ä¿æŠ¤Sourceå¼•ç”¨æ ¼å¼ï¼Œä¸è¦æ›¿æ¢å…¶ä¸­çš„æ–¹æ‹¬å·
        import re

        # å…ˆæå–æ‰€æœ‰Sourceå¼•ç”¨
        source_pattern = r'\[Sources?:\s*[T\d\s,]+\]'
        sources = re.findall(source_pattern, llm_output)

        # ä¸´æ—¶æ›¿æ¢Sourceå¼•ç”¨ä¸ºå ä½ç¬¦
        temp_llm_output = llm_output
        source_placeholders = {}
        for i, source in enumerate(sources):
            placeholder = f"__SOURCE_PLACEHOLDER_{i}__"
            source_placeholders[placeholder] = source
            temp_llm_output = temp_llm_output.replace(source, placeholder)

        # æ›¿æ¢å…¶ä»–å¯èƒ½å¯¼è‡´Markdowné“¾æ¥å†²çªçš„æ–¹æ‹¬å·
        cleaned = temp_llm_output.replace('[', 'ã€').replace(']', 'ã€‘')

        # æ¢å¤Sourceå¼•ç”¨
        for placeholder, original_source in source_placeholders.items():
            cleaned = cleaned.replace(placeholder, original_source)

        # ç¡®ä¿è¡Œå°¾æœ‰é€‚å½“çš„ç©ºæ ¼ç”¨äºæ¢è¡Œ
        lines = cleaned.split('\n')
        processed_lines = []

        for line in lines:
            # å¯¹äºä»¥*å¼€å¤´çš„æ–œä½“è¡Œï¼Œåœ¨è¡Œå°¾æ·»åŠ ç©ºæ ¼ä»¥ç¡®ä¿æ¢è¡Œ
            if line.strip().startswith('*') and line.strip().endswith('*'):
                processed_lines.append(line.rstrip() + '  ')
            else:
                processed_lines.append(line)

        return '\n'.join(processed_lines)

    def _format_posts_for_llm(self, posts: List[Dict[str, Any]], source_prefix: str = 'T') -> Tuple[str, List[Dict[str, Any]]]:
        """
        å°†å¸–å­æ ¼å¼åŒ–ä¸ºå¸¦ç¼–å·çš„ç´§å‡‘æ–‡æœ¬ï¼Œæ ¹æ®context_modeå’Œåª’ä½“æƒ…å†µæ™ºèƒ½åŒ…å«è§£è¯»ä¿¡æ¯

        ä¼˜åŒ–ç­–ç•¥ï¼š
        - lightæ¨¡å¼ï¼šä»…å¯¹å›¾æ–‡å¸–ä¿ç•™è§£è¯»ï¼Œçº¯æ–‡æœ¬å¸–åªä¿ç•™åŸæ–‡ï¼ˆå‹ç¼©ä¸Šä¸‹æ–‡ï¼‰
        - fullæ¨¡å¼ï¼šæ‰€æœ‰å¸–å­éƒ½åŒ…å«è§£è¯»ï¼ˆä¿æŒå®Œæ•´ä¿¡æ¯ï¼‰
        - æ¸…ç†å›¾ç‰‡URLï¼Œå‡å°‘tokenæ¶ˆè€—

        Args:
            posts: å¸–å­æ•°æ®åˆ—è¡¨
            source_prefix: æ¥æºIDå‰ç¼€

        Returns:
            (æ ¼å¼åŒ–åçš„æ–‡æœ¬, æºæ˜ å°„åˆ—è¡¨)
        """
        lines: List[str] = []
        sources: List[Dict[str, Any]] = []
        total_chars = 0

        for idx, p in enumerate(posts, 1):
            sid = f"{source_prefix}{idx}"
            nickname = p.get('nickname') or p.get('jike_user_id') or 'æœªçŸ¥ä½œè€…'
            link = p.get('link') or ''

            # è·å–åŸå§‹å†…å®¹
            summary = p.get('summary') or ''

            # æ£€æŸ¥æ˜¯å¦æœ‰åª’ä½“
            has_media = self._post_has_media(p)

            # è®¡ç®—åª’ä½“æ•°é‡
            media_count = self._get_media_count(p) if has_media else 0

            # æ¸…ç†å›¾ç‰‡URLï¼Œå‹ç¼©ä¸Šä¸‹æ–‡
            summary = self._clean_image_urls_from_content(summary, media_count)

            # å†³å®šæ˜¯å¦åŒ…å«è§£è¯»
            # lightæ¨¡å¼ï¼šåªå¯¹æœ‰åª’ä½“çš„å¸–å­åŒ…å«è§£è¯»
            # fullæ¨¡å¼ï¼šæ‰€æœ‰å¸–å­éƒ½åŒ…å«è§£è¯»
            include_interpretation = (self.context_mode == 'full') or (self.context_mode == 'light' and has_media)

            # è·å–è§£è¯»ä¿¡æ¯
            interpretation_text = ''
            interpretation_model = ''
            if include_interpretation:
                interpretation_text = p.get('interpretation_text') or ''
                interpretation_model = p.get('interpretation_model') or ''

            # æˆªæ–­å¤„ç†
            summary_t = self._truncate(summary, 1500)
            interpretation_t = self._truncate(interpretation_text, 3000) if interpretation_text else ''

            # æ„å»ºç´§å‡‘çš„å¸–å­å—
            if include_interpretation and interpretation_text:
                # æœ‰è§£è¯»çš„æ ¼å¼ï¼šæ›´ç´§å‡‘
                block = f"[{sid} @{nickname}]\n{summary_t}\nâ†’ æ´å¯Ÿ: {interpretation_t}"
            else:
                # çº¯æ–‡æœ¬æ ¼å¼ï¼šæç®€
                block = f"[{sid} @{nickname}]\n{summary_t}"

            # æ£€æŸ¥é•¿åº¦é™åˆ¶
            if total_chars + len(block) > self.max_content_length:
                self.logger.info(f"è¾¾åˆ°æœ€å¤§å†…å®¹é™åˆ¶({self.max_content_length}),æˆªæ–­å¸–å­åˆ—è¡¨äºç¬¬ {idx-1} æ¡")
                break

            lines.append(block)
            total_chars += len(block)

            # æ„å»ºæ¥æºæ˜ å°„ï¼ˆç”¨äºåç»­ç”Ÿæˆæ¥æºæ¸…å•ï¼‰
            title = p.get('title') or ''
            title_t = self._truncate(title, 140)
            sources.append({
                'sid': sid,
                'title': title_t or self._truncate(summary, 100),
                'link': link,
                'nickname': nickname,
                'excerpt': self._truncate(summary, 120)
            })

        return "\n\n---\n\n".join(lines), sources

    def _format_daily_reports_for_weekly(self, daily_reports: List[Dict[str, Any]]) -> Tuple[str, List[Dict[str, Any]]]:
        """å°†æ¯æ—¥çƒ­ç‚¹æŠ¥å‘Šåˆæˆä¸ºå‘¨æŠ¥è¾“å…¥ä¸Šä¸‹æ–‡"""
        if not daily_reports:
            return "", []

        lines: List[str] = []
        sources: List[Dict[str, Any]] = []

        for idx, report in enumerate(daily_reports, 1):
            label = f"D{idx}"
            title = report.get('report_title') or f"Daily Hotspot #{idx}"
            items = report.get('items_analyzed') or 0

            start_dt = report.get('analysis_period_start')
            end_dt = report.get('analysis_period_end')

            if isinstance(start_dt, datetime):
                start_str = start_dt.strftime('%Y-%m-%d %H:%M')
            else:
                start_str = str(start_dt)

            if isinstance(end_dt, datetime):
                end_str = end_dt.strftime('%Y-%m-%d %H:%M')
                date_label = end_dt.strftime('%Y-%m-%d')
            else:
                end_str = str(end_dt)
                date_label = str(end_dt)

            lines.append(f"## {label} Â· {date_label} Â· {title}")
            lines.append("")
            lines.append(f"*è¦†ç›–åŒºé—´*: {start_str} - {end_str}  |  *æ±‡æ€»åŠ¨æ€*: {items} æ¡")
            lines.append("")

            report_content = (report.get('report_content') or "").strip()
            if report_content:
                lines.append(report_content)
                lines.append("")

            lines.append("---")
            lines.append("")

            sources.append({
                'sid': label,
                'title': title,
                'link': '',
                'nickname': date_label,
                'excerpt': self._truncate(title, 80)
            })

        while lines and lines[-1] == "":
            lines.pop()
        if lines and lines[-1] == "---":
            lines.pop()

        return "\n".join(lines), sources

    def _render_sources_section(self, sources: List[Dict[str, Any]]) -> str:
        if not sources:
            return ""

        lines = ["## ğŸ“š æ¥æºæ¸…å• (Source List)", ""]
        for s in sources:
            # æ¸…ç†æ ‡é¢˜ä¸­çš„æ–¹æ‹¬å·ï¼Œé¿å…ä¸Markdowné“¾æ¥å†²çª
            clean_title = (s.get('title') or s.get('excerpt') or '').replace('[', 'ã€').replace(']', 'ã€‘')
            nickname = s.get('nickname') or ''
            if nickname:
                nickname_display = f"@{nickname}"
            else:
                nickname_display = ""

            link = s.get('link')
            if link:
                actor_part = f"[{nickname_display}]({link})" if nickname_display else f"[æ¥æº]({link})"
            else:
                actor_part = nickname_display or "æ¥æº"

            lines.append(f"- **ã€{s.get('sid')}ã€‘**: {actor_part}: {clean_title}")
        return "\n".join(lines)

    def _enhance_source_links(self, report_content: str, sources: List[Dict[str, Any]]) -> str:
        """
        å¢å¼ºæŠ¥å‘Šä¸­çš„æ¥æºé“¾æ¥ï¼Œå°† [Source: T1, T2] ä¸­çš„æ¯ä¸ª Txx è½¬æ¢ä¸ºå¯ç‚¹å‡»çš„é“¾æ¥
        """
        import re

        # æ„å»ºæ¥æºIDåˆ°é“¾æ¥çš„æ˜ å°„
        source_link_map = {s['sid']: s['link'] for s in sources}

        def replace_source_refs(match):
            # æå–å®Œæ•´çš„ Source å¼•ç”¨å†…å®¹
            full_source_text = match.group(0)  # å¦‚ "[Source: T2, T9, T18]"
            source_content = match.group(1)    # å¦‚ "T2, T9, T18"

            # åˆ†å‰²å¹¶å¤„ç†æ¯ä¸ªæ¥æºID
            source_ids = [sid.strip() for sid in source_content.split(',')]
            linked_sources = []

            for sid in source_ids:
                if sid in source_link_map:
                    # å°† Txx è½¬æ¢ä¸ºé“¾æ¥
                    linked_sources.append(f"[{sid}]({source_link_map[sid]})")
                else:
                    # å¦‚æœæ‰¾ä¸åˆ°å¯¹åº”é“¾æ¥ï¼Œä¿æŒåŸæ ·
                    linked_sources.append(sid)

            # é‡æ–°ç»„åˆ
            return f"ğŸ“ [Source: {', '.join(linked_sources)}]"

        # æŸ¥æ‰¾æ‰€æœ‰ [Source: ...] æˆ– [Sources: ...] æ¨¡å¼å¹¶æ›¿æ¢
        pattern = r'\[Sources?:\s*([T\d\s,]+)\]'
        enhanced_content = re.sub(pattern, replace_source_refs, report_content)

        return enhanced_content

    # ---------- Prompt æ¨¡æ¿ ----------
    def _prompt_daily_briefing(self) -> str:
        """æ„å»º"å³åˆ»æ—¥æŠ¥èµ„è®¯"å¼çš„ç®€æŠ¥æç¤ºè¯ï¼Œå¼ºè°ƒå…¨é¢æ€§å’Œåˆ†ç±»èšåˆ"""

        # æ ¹æ®context_modeåŠ¨æ€ç”Ÿæˆæ•°æ®æ ¼å¼æè¿°
        if self.context_mode == 'light':
            data_format_description = """# Input Data Format:
ä½ å°†æ”¶åˆ°ä¸€ç³»åˆ—ç»è¿‡é¢„å¤„ç†çš„å¸–å­ã€‚çº¯æ–‡æœ¬å¸–åªåŒ…å«åŸæ–‡ï¼›å›¾æ–‡å¸–ä¼šé¢å¤–é™„å¸¦AIç”Ÿæˆçš„`â†’ æ´å¯Ÿ:`ã€‚
- çº¯æ–‡æœ¬å¸–: `[T_id @user_handle]` + å¸–å­åŸæ–‡
- å›¾æ–‡å¸–: `[T_id @user_handle]` + å¸–å­åŸæ–‡ + `â†’ æ´å¯Ÿ: {{AIè§£è¯»}}`"""
        else:  # full mode
            data_format_description = """# Input Data Format:
ä½ å°†æ”¶åˆ°ä¸€ç³»åˆ—ç»è¿‡é¢„å¤„ç†çš„å¸–å­ã€‚æ¯æ¡å¸–å­éƒ½åŒ…å«åŸæ–‡å’ŒAIç”Ÿæˆçš„`â†’ æ´å¯Ÿ:`ã€‚
- æ ¼å¼: `[T_id @user_handle]` + å¸–å­åŸæ–‡ + `â†’ æ´å¯Ÿ: {{AIè§£è¯»}}`"""

        return f"""# Role: èµ„æ·±ç§‘æŠ€ç¤¾åŒºåˆ†æå¸ˆï¼Œä¸“æ³¨äºä»å³åˆ»ç¤¾åŒºå‘æ˜ä»·å€¼ä¿¡æ¯

# Context:
ä½ æ­£åœ¨ä¸ºå¿™ç¢Œçš„ç§‘æŠ€ä»ä¸šè€…ã€äº§å“ç»ç†å’ŒæŠ•èµ„è€…ç¼–å†™ä¸€ä»½å³åˆ»ç¤¾åŒºæ¯æ—¥å¿«è®¯ã€‚ä½ çš„ç›®æ ‡æ˜¯å¿«é€Ÿã€ç²¾å‡†åœ°æ•æ‰ç¤¾åŒºå†…çš„äº§å“çµæ„Ÿã€æŠ€æœ¯æ€è€ƒã€è¡Œä¸šè¶‹åŠ¿å’Œæœ‰ä»·å€¼çš„è®¨è®ºï¼Œè€Œä¸æ˜¯ç®€å•åœ°ç½—åˆ—æ–°é—»ã€‚

# Core Principles:
1. **ä»·å€¼ä¼˜å…ˆ (Value First)**: ä¼˜å…ˆæ”¶å½•å…·æœ‰å¯å‘æ€§çš„æ€è€ƒã€æ–°é¢–çš„è§‚ç‚¹å’Œé«˜ä»·å€¼çš„èµ„æºã€‚
2. **åˆ†ç±»æ¸…æ™° (Clear Categorization)**: ä¸¥æ ¼æŒ‰ç…§å³åˆ»ç¤¾åŒºçš„ç‰¹è‰²ä¸»é¢˜è¿›è¡Œåˆ†ç±»ï¼Œä¾¿äºè¯»è€…å¿«é€Ÿå®šä½è‡ªå·±æ„Ÿå…´è¶£çš„å†…å®¹ã€‚
3. **è¯¦ç•¥å¾—å½“ (Appropriate Detail)**: æ¯æ¡ä¿¡æ¯éƒ½åº”æä¾›è¶³å¤Ÿä¸Šä¸‹æ–‡ï¼Œç¡®ä¿è¯»è€…èƒ½ç†è§£å…¶æ ¸å¿ƒä»·å€¼ã€‚é¿å…è¿‡åº¦å‹ç¼©ï¼Œä½†ä¿æŒç²¾ç‚¼ã€‚
4. **ç»å¯¹å¯è¿½æº¯ (Absolute Traceability)**: æ¯æ¡ä¿¡æ¯å¿…é¡»åœ¨æœ«å°¾æ ‡æ³¨æ¥æº `[Source: T_n]`ã€‚

{data_format_description}

# Your Task:
ç”Ÿæˆä¸€ä»½ç»“æ„åŒ–çš„æ—¥æŠ¥èµ„è®¯ï¼Œä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹Markdownæ ¼å¼ã€‚è¯·æ³¨æ„ï¼Œä½ çš„ä»»åŠ¡æ˜¯ä¿¡æ¯èšåˆä¸æç‚¼ï¼Œè€Œéæ·±åº¦åˆ†æã€‚

## ğŸš€ äº§å“ä¸åŠ¨æ€
*æ–°äº§å“å‘å¸ƒã€åŠŸèƒ½æ›´æ–°ã€å¢é•¿ç­–ç•¥ã€ç”¨æˆ·ä½“éªŒè®¨è®º*
- **[äº§å“/åŠŸèƒ½å]**: è¯¦ç»†ä»‹ç»å…¶æ ¸å¿ƒåŠ¨æ€ã€ç”¨æˆ·åé¦ˆæˆ–å¢é•¿ç­–ç•¥ï¼Œç¡®ä¿ä¿¡æ¯å®Œæ•´ (50-200å­—) [Source: T_n]

---

## ğŸ’¡ æŠ€æœ¯ä¸æ€è€ƒ
*æ–°æŠ€æœ¯å®è·µã€åº•å±‚é€»è¾‘æ€è€ƒã€å¼€å‘ç»éªŒã€æ–¹æ³•è®ºåˆ†äº«*
- **[æŠ€æœ¯ç‚¹/æ€è€ƒç‚¹]**: æ¸…æ™°é˜è¿°å…¶æ ¸å¿ƒè§‚ç‚¹ã€æŠ€æœ¯ç»†èŠ‚æˆ–æ–¹æ³•è®ºï¼Œæä¾›è¶³å¤ŸèƒŒæ™¯ (50-200å­—) [Source: T_n]

---

## ğŸ“ˆ è¡Œä¸šä¸è¶‹åŠ¿
*è¡Œä¸šæ–°é—»æ´å¯Ÿã€å¸‚åœºåˆ†æã€å•†ä¸šæ¨¡å¼æ¢è®¨ã€æŠ•èèµ„åŠ¨æ€*
- **[è§‚å¯Ÿç‚¹]**: é˜è¿°å…³é”®ä¿¡æ¯ã€æ•°æ®å’Œä½ çš„è§£è¯»ï¼Œè¯´æ˜å…¶å¯¹è¡Œä¸šçš„å½±å“ (50-200å­—) [Source: T_n]

---

## ğŸ’¬ ç¤¾åŒºçƒ­è®®
*ç¤¾åŒºå†…å¹¿æ³›è®¨è®ºçš„æ–‡åŒ–ç°è±¡ã€å…¬å…±äº‹ä»¶æˆ–çƒ­é—¨è¯é¢˜*
- **[è¯é¢˜å]**: è¯¦ç»†æ€»ç»“è®¨è®ºçš„ç„¦ç‚¹ã€ä¸åŒè§‚ç‚¹å’Œç¤¾åŒºæƒ…ç»ªï¼Œè®©è¯»è€…äº†è§£å…¨è²Œ (50-200å­—) [Source: T_n]

---

## ğŸŒŸ ç²¾é€‰è§‚ç‚¹ä¸èµ„æº
*å€¼å¾—å…³æ³¨çš„ç‹¬ç‰¹è§è§£ã€æœ‰è¶£æƒ³æ³•æˆ–é«˜ä»·å€¼å·¥å…·/æ–‡ç« åˆ†äº«*
- **[@ç”¨æˆ·]**: æ¸…æ™°é˜è¿°å…¶æ ¸å¿ƒè§‚ç‚¹ã€è®ºæ®å’Œå¯å‘æ„ä¹‰ (50-200å­—) [Source: T_n]
- **[èµ„æºåç§°]**: è¯¦ç»†è¯´æ˜å…¶ç”¨é€”ã€ç‰¹ç‚¹å’Œæ¨èç†ç”± (50-200å­—) [Source: T_m]

# Input Data:
{{content}}

# Important Notes:
1. **å¦‚æœæŸä¸ªåˆ†ç±»ä¸‹æœ‰ä¸°å¯Œçš„å†…å®¹ï¼Œè¯·å°½å¯èƒ½å…¨é¢åœ°æ”¶å½•ï¼Œä¸è¦é—æ¼ã€‚**
2. **å¦‚æœå†…å®¹è¾ƒå°‘ï¼Œç¡®ä¿è‡³å°‘æœ‰3-5æ¡ç²¾åä¿¡æ¯ã€‚**
3. **å¦‚æœæŸä¸ªåˆ†ç±»ä¸‹å®Œå…¨æ²¡æœ‰ç›¸å…³å†…å®¹ï¼Œåˆ™åœ¨æœ€ç»ˆæŠ¥å‘Šä¸­çœç•¥è¯¥åˆ†ç±»ã€‚**
4. æ¯æ¡ä¿¡æ¯éƒ½å¿…é¡»æœ‰ `[Source: T_n]` æ ‡æ³¨ã€‚
5. **å†…å®¹ä¸ºç‹**: ç¡®ä¿æ¯æ¡ä¿¡æ¯çš„æè¿°è¶³å¤Ÿæ¸…æ™°ã€å®Œæ•´ï¼Œèƒ½å¤Ÿç‹¬ç«‹æˆæ–‡ã€‚å¯¹äºå¤æ‚æˆ–é‡è¦çš„åŠ¨æ€ï¼Œå®å¯ç¯‡å¹…ç¨é•¿ï¼Œä¹Ÿè¦è¯´æ¸…æ¥šæ¥é¾™å»è„‰å’Œæ ¸å¿ƒä»·å€¼ã€‚
"""

    def _prompt_daily(self) -> str:
        """æ„å»ºæ—¥æŠ¥æç¤ºè¯ï¼Œæ ¹æ®context_modeè°ƒæ•´æ•°æ®æ ¼å¼è¯´æ˜"""

        # æ ¹æ®context_modeç”Ÿæˆç²¾ç¡®çš„æ•°æ®æ ¼å¼æè¿°
        if self.context_mode == 'light':
            data_format_description = """# Input Data Format:
ä½ å°†æ”¶åˆ°ä¸€ç³»åˆ—ç»è¿‡é¢„å¤„ç†çš„å¸–å­ï¼Œé‡‡ç”¨ç´§å‡‘æ ¼å¼ä»¥ä¼˜åŒ–ä¸Šä¸‹æ–‡ã€‚æ¯æ¡å¸–å­åŒ…å«åŸå§‹æ–‡æœ¬å†…å®¹ï¼›åªæœ‰å½“å¸–å­åŒ…å«å›¾ç‰‡æˆ–å¤šåª’ä½“æ—¶ï¼Œæ‰ä¼šé¢å¤–é™„å¸¦AIæ·±åº¦æ´å¯Ÿã€‚

**æ ¼å¼è¯´æ˜**ï¼š
- çº¯æ–‡æœ¬å¸–ï¼š`[T_id @user_handle]` + æ¢è¡Œ + å¸–å­åŸæ–‡
- å›¾æ–‡å¸–ï¼š`[T_id @user_handle]` + æ¢è¡Œ + å¸–å­åŸæ–‡ + æ¢è¡Œ + `â†’ æ´å¯Ÿ: AIç”Ÿæˆçš„ç»¼åˆè§£è¯»`

**é‡è¦**ï¼š
1. T_id æ˜¯æ¥æºæ ‡è¯†ç¬¦ï¼Œä½ åœ¨åˆ†æä¸­å¼•ç”¨æ—¶ä½¿ç”¨ `[Source: T_id]` æ ¼å¼
2. å¯¹äºçº¯æ–‡æœ¬å¸–ï¼Œè¯·ç›´æ¥åŸºäºåŸæ–‡è¿›è¡Œåˆ†æ
3. å¯¹äºå›¾æ–‡å¸–ï¼Œè¯·ç»¼åˆåŸæ–‡å’Œæ´å¯Ÿå†…å®¹è¿›è¡Œåˆ†æ"""
        else:  # full mode
            data_format_description = """# Input Data Format:
ä½ å°†æ”¶åˆ°ä¸€ç³»åˆ—ç»è¿‡é¢„å¤„ç†çš„å¸–å­ï¼Œé‡‡ç”¨ç´§å‡‘æ ¼å¼ä»¥ä¼˜åŒ–ä¸Šä¸‹æ–‡ã€‚æ¯æ¡å¸–å­éƒ½åŒ…å«åŸå§‹å†…å®¹å’ŒAIç”Ÿæˆçš„æ·±åº¦æ´å¯Ÿã€‚

**æ ¼å¼è¯´æ˜**ï¼š
`[T_id @user_handle]` + æ¢è¡Œ + å¸–å­åŸæ–‡ + æ¢è¡Œ + `â†’ æ´å¯Ÿ: LLMç”Ÿæˆçš„æ·±åº¦è§£è¯»`

**é‡è¦**ï¼š
1. T_id æ˜¯æ¥æºæ ‡è¯†ç¬¦ï¼Œä½ åœ¨åˆ†æä¸­å¼•ç”¨æ—¶ä½¿ç”¨ `[Source: T_id]` æ ¼å¼
2. è¯·ç»¼åˆåˆ©ç”¨åŸæ–‡å’Œæ´å¯Ÿä¸¤éƒ¨åˆ†ä¿¡æ¯è¿›è¡Œåˆ†æ
3. æ´å¯Ÿéƒ¨åˆ†æ˜¯AIå¯¹å¸–å­çš„æ·±åº¦è§£è¯»ï¼Œæ˜¯ä½ åˆ†æçš„æ ¸å¿ƒä¾æ®"""

        return f"""# Role: èµ„æ·±ç¤¾åŒºæˆ˜ç•¥åˆ†æå¸ˆ

# Context:
ä½ æ­£åœ¨åˆ†æä¸€ä¸ªç”±æŠ€æœ¯ä¸“å®¶ã€äº§å“ç»ç†ã€æŠ•èµ„äººå’Œåˆ›ä¸šè€…ç»„æˆçš„ç²¾è‹±ç¤¾åŒºâ€”â€”'å³åˆ»'åœ¨è¿‡å»24å°æ—¶å†…å‘å¸ƒçš„å¸–å­ã€‚ä½ çš„ä»»åŠ¡æ˜¯åŸºäºæˆ‘æä¾›çš„ã€å·²ç¼–å·çš„åŸå§‹è®¨è®ºææ–™å’ŒAIæ·±åº¦æ´å¯Ÿï¼ˆå¦‚æœ‰ï¼‰ï¼Œæ’°å†™ä¸€ä»½ä¿¡æ¯å¯†åº¦é«˜ã€å†…å®¹è¯¦å°½ã€å¯è¯»æ€§å¼ºçš„æƒ…æŠ¥ç®€æŠ¥ã€‚

# Core Principles:
1.  **ä»·å€¼å¯¼å‘ä¸æ·±åº¦ä¼˜å…ˆ**: ä½ çš„æ ¸å¿ƒç›®æ ‡æ˜¯æŒ–æ˜å‡ºå¯¹ä»ä¸šè€…æœ‰ç›´æ¥ä»·å€¼çš„ä¿¡æ¯ã€‚åœ¨æ’°å†™æ¯ä¸ªéƒ¨åˆ†æ—¶ï¼Œéƒ½åº”è¿½æ±‚å†…å®¹çš„**æ·±åº¦å’Œå®Œæ•´æ€§**ï¼Œ**é¿å…è¿‡äºç®€çŸ­çš„æ¦‚æ‹¬**ã€‚
2.  **æ·±åº¦åˆæˆ (Deep Synthesis)**: ä¸è¦ç®€å•ç½—åˆ—ã€‚ä½ éœ€è¦å°†ä¸åŒæ¥æºçš„ä¿¡æ¯ç‚¹è¿æ¥èµ·æ¥ï¼Œæ„å»ºæˆæœ‰æ„ä¹‰çš„å™äº‹ï¼ˆNarrativeï¼‰ã€‚
3.  **æ³¨å…¥æ´è§ (Inject Insight)**: ä½ ä¸æ˜¯ä¸€ä¸ªæ€»ç»“è€…ï¼Œè€Œæ˜¯ä¸€ä¸ªåˆ†æå¸ˆã€‚åœ¨é™ˆè¿°äº‹å®å’Œè§‚ç‚¹çš„åŸºç¡€ä¸Šï¼Œ**å¿…é¡»**åŠ å…¥ä½ è‡ªå·±çš„ã€åŸºäºä¸Šä¸‹æ–‡çš„ã€æœ‰æ·±åº¦çš„åˆ†æå’Œè¯„è®ºã€‚
4.  **ç»å¯¹å¯è¿½æº¯ (Absolute Traceability)**: ä½ çš„æ¯ä¸€æ¡æ´å¯Ÿã€åˆ¤æ–­å’Œå»ºè®®ï¼Œéƒ½å¿…é¡»åœ¨å¥æœ«ä½¿ç”¨ `[Source: T_n]` æˆ– `[Sources: T_n, T_m]` çš„æ ¼å¼æ˜ç¡®æ ‡æ³¨ä¿¡æ¯æ¥æºã€‚è¿™æ˜¯ç¡¬æ€§è¦æ±‚,ç»å¯¹ä¸èƒ½é—æ¼ã€‚
5.  **è¯†åˆ«å¸–å­ç±»å‹**: åœ¨åˆ†ææ—¶ï¼Œè¯·æ³¨æ„è¯†åˆ«æ¯ä¸ªä¸»é¢˜çš„æ½œåœ¨ç±»å‹ï¼Œä¾‹å¦‚ï¼š`[AI/å‰æ²¿æŠ€æœ¯]`, `[äº§å“ä¸è®¾è®¡]`, `[åˆ›ä¸šä¸æŠ•èµ„]`, `[ä¸ªäººæˆé•¿ä¸æ€è€ƒ]`, `[è¡Œä¸šä¸å¸‚åœºåŠ¨æ€]`, `[å·¥å…·ä¸å·¥ä½œæµåˆ†äº«]`ç­‰ã€‚è¿™æœ‰åŠ©äºä½ åˆ¤æ–­å…¶æ ¸å¿ƒä»·å€¼ã€‚

---

{data_format_description}

---

# Input Data (å¸–å­æ•°æ®ï¼Œå·²ç¼–å·):
{{content}}

---

# Your Task:
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ç»“æ„å’Œè¦æ±‚ï¼Œç”Ÿæˆä¸€ä»½å†…å®¹ä¸°å¯Œè¯¦å®çš„å®Œæ•´MarkdownæŠ¥å‘Šã€‚

**ç¬¬ä¸€éƒ¨åˆ†ï¼šæœ¬æ—¶æ®µç„¦ç‚¹é€ŸæŠ¥ (Top Topics Overview)**
*   ä»»åŠ¡ï¼šé€šè¯»æ‰€æœ‰ææ–™ï¼Œä¸ºæ¯ä¸ªå€¼å¾—å…³æ³¨çš„æ ¸å¿ƒä¸»é¢˜æ’°å†™ä¸€ä»½**è¯¦ç»†æ‘˜è¦**ã€‚
*   è¦æ±‚ï¼šä¸ä»…è¦æ€»ç»“ä¸»é¢˜çš„æ ¸å¿ƒå†…å®¹ï¼Œè¿˜è¦**å°½å¯èƒ½å…¨é¢åœ°**åˆ—å‡ºä¸»è¦çš„è®¨è®ºæ–¹å‘å’Œå…³é”®è§‚ç‚¹ã€‚ç¯‡å¹…æ— éœ€ä¸¥æ ¼é™åˆ¶ï¼ŒåŠ›æ±‚å…¨é¢ã€‚

**ç¬¬äºŒéƒ¨åˆ†ï¼šæ ¸å¿ƒæ´å¯Ÿä¸è¶‹åŠ¿ (Executive Summary & Trends)**
*   ä»»åŠ¡ï¼šåŸºäºç¬¬ä¸€éƒ¨åˆ†çš„æ‰€æœ‰ä¿¡æ¯ï¼Œä»å…¨å±€è§†è§’æç‚¼å‡ºå…³é”®æ´å¯Ÿä¸è¶‹åŠ¿ã€‚
*   è¦æ±‚ï¼š
    *   **æ ¸å¿ƒæ´å¯Ÿ**: **å°½å¯èƒ½å…¨é¢åœ°**æç‚¼ä½ å‘ç°çš„é‡è¦è¶‹åŠ¿æˆ–æ´å¯Ÿï¼Œå¹¶è¯¦ç»†é˜è¿°ï¼Œ**ä¸è¦å±€é™äºå°‘æ•°å‡ ç‚¹**ã€‚
    *   **æŠ€æœ¯é£å‘ä¸å·¥å…·ç®±**: **è¯¦ç»†åˆ—å‡ºå¹¶ä»‹ç»**è¢«çƒ­è®®çš„æ–°æŠ€æœ¯ã€æ–°æ¡†æ¶æˆ–å·¥å…·ã€‚å¯¹äºæ¯ä¸ªé¡¹ç›®ï¼Œè¯·æä¾›æ›´è¯¦å°½çš„æè¿°ï¼ŒåŒ…æ‹¬å…¶ç”¨é€”ã€ä¼˜ç‚¹ã€ä»¥åŠç¤¾åŒºè®¨è®ºä¸­çš„å…·ä½“è¯„ä»·ã€‚
    *   **ç¤¾åŒºçƒ­è®®ä¸éœ€æ±‚ç‚¹**: **è¯¦ç»†å±•å¼€**ç¤¾åŒºæ™®éå…³å¿ƒçš„è¯é¢˜ã€é‡åˆ°çš„ç—›ç‚¹æˆ–æ½œåœ¨çš„éœ€æ±‚ï¼Œè¯´æ˜å…¶èƒŒæ™¯ã€å½“å‰è®¨è®ºçš„ç„¦ç‚¹ä»¥åŠæ½œåœ¨çš„å½±å“ã€‚

**ç¬¬ä¸‰éƒ¨åˆ†ï¼šä»·å€¼ä¿¡æ¯æŒ–æ˜ (Valuable Information Mining)**
*   ä»»åŠ¡ï¼šæ·±å…¥æŒ–æ˜å¸–å­ä¸­çš„é«˜ä»·å€¼ä¿¡æ¯ï¼Œå¹¶è¿›è¡Œè¯¦ç»†ä»‹ç»ã€‚
*   è¦æ±‚ï¼š
    *   **é«˜ä»·å€¼èµ„æº/å·¥å…·**: **è¯¦ç»†åˆ—å‡ºå¹¶ä»‹ç»**è®¨è®ºä¸­å‡ºç°çš„å¯ä»¥ç›´æ¥ä½¿ç”¨çš„è½¯ä»¶ã€åº“ã€APIã€å¼€æºé¡¹ç›®æˆ–å­¦ä¹ èµ„æ–™ã€‚åŒ…æ‹¬èµ„æºçš„ç”¨é€”å’Œç¤¾åŒºè¯„ä»·ã€‚
    *   **æœ‰è¶£è§‚ç‚¹/æ·±åº¦è®¨è®º**: **è¯¦ç»†é˜è¿°**é‚£äº›å¼•äººæ·±æ€ã€å…·æœ‰å¯å‘æ€§çš„ä¸ªäººè§‚ç‚¹æˆ–é«˜è´¨é‡çš„è®¨è®ºã€‚åˆ†æè¯¥è§‚ç‚¹ä¸ºä½•é‡è¦æˆ–å…·æœ‰å¯å‘æ€§ã€‚

**ç¬¬å››éƒ¨åˆ†ï¼šè¡ŒåŠ¨å»ºè®® (Actionable Recommendations)**
*   ä»»åŠ¡ï¼šåŸºäºä»¥ä¸Šæ‰€æœ‰åˆ†æï¼Œä¸ºç¤¾åŒºä¸­çš„ä¸åŒè§’è‰²æä¾›ä¸°å¯Œä¸”å…·ä½“çš„å»ºè®®ã€‚
*   è¦æ±‚ï¼šå»ºè®®å¿…é¡»æœ‰é«˜åº¦çš„é’ˆå¯¹æ€§ï¼Œå¹¶é˜è¿°å…¶èƒŒåçš„é€»è¾‘å’Œé¢„æœŸæ•ˆæœã€‚
    *   **ç»™äº§å“ç»ç†çš„å»ºè®®**: ...
    *   **ç»™åˆ›ä¸šè€…/æŠ•èµ„è€…çš„å»ºè®®**: ...
    *   **ç»™æŠ€æœ¯ä»ä¸šè€…çš„å»ºè®®**: ...

---

# Output Format (Strictly follow this Markdown structure):

## ä¸€ã€æœ¬æ—¶æ®µç„¦ç‚¹é€ŸæŠ¥

### **1. [ä¸»é¢˜Açš„æ ‡é¢˜]**
*   **è¯¦ç»†æ‘˜è¦**: [è¯¦ç»†æ‘˜è¦è¯¥ä¸»é¢˜çš„æ ¸å¿ƒå†…å®¹ï¼Œå¹¶åˆ—å‡ºä¸»è¦çš„è®¨è®ºæ–¹å‘å’Œå…³é”®è§‚ç‚¹ã€‚ç¯‡å¹…æ— éœ€ä¸¥æ ¼é™åˆ¶ï¼ŒåŠ›æ±‚å…¨é¢ã€‚] [Source: T_n]

### **2. [ä¸»é¢˜Bçš„æ ‡é¢˜]**
*   **è¯¦ç»†æ‘˜è¦**: [åŒä¸Šã€‚] [Source: T_m]

...(ç½—åˆ—æ‰€æœ‰ä½ è®¤ä¸ºå€¼å¾—æŠ¥å‘Šçš„çƒ­é—¨ä¸»é¢˜)

---

## äºŒã€æ ¸å¿ƒæ´å¯Ÿä¸è¶‹åŠ¿

*   **æ ¸å¿ƒæ´å¯Ÿ**:
    *   [è¯¦ç»†é˜è¿°ä½ å‘ç°çš„ä¸€ä¸ªé‡è¦è¶‹åŠ¿æˆ–æ´å¯Ÿã€‚ä¾‹å¦‚ï¼šAI Agentçš„å®ç°å’Œåº”ç”¨æˆä¸ºæ–°çš„æŠ€æœ¯ç„¦ç‚¹ï¼Œç¤¾åŒºå†…æ¶Œç°äº†å¤šä¸ªå›´ç»•æ­¤å±•å¼€çš„å¼€æºé¡¹ç›®å’Œå®è·µè®¨è®ºï¼Œå…·ä½“è¡¨ç°åœ¨...] [Sources: T2, T9]
    *   [è¯¦ç»†é˜è¿°ç¬¬äºŒä¸ªé‡è¦æ´å¯Ÿã€‚] [Sources: T3, T7]
    *   ...(å°½å¯èƒ½å¤šåœ°åˆ—å‡ºæ´å¯Ÿ)

*   **æŠ€æœ¯é£å‘ä¸å·¥å…·ç®±**:
    *   **[æŠ€æœ¯/å·¥å…·A]**: [è¯¦ç»†ä»‹ç»å®ƒæ˜¯ä»€ä¹ˆï¼Œä¸ºä»€ä¹ˆå®ƒç°åœ¨å¾ˆçƒ­é—¨ï¼Œç¤¾åŒºæˆå‘˜å¦‚ä½•è¯„ä»·å®ƒï¼Œä»¥åŠå®ƒè§£å†³äº†ä»€ä¹ˆå…·ä½“é—®é¢˜ã€‚] [Source: T3]
    *   **[æŠ€æœ¯/å·¥å…·B]**: [åŒä¸Šã€‚] [Source: T7]
    *   ...(å°½å¯èƒ½å¤šåœ°åˆ—å‡ºæŠ€æœ¯/å·¥å…·)

*   **ç¤¾åŒºçƒ­è®®ä¸éœ€æ±‚ç‚¹**:
    *   **[çƒ­è®®è¯é¢˜A]**: [è¯¦ç»†å±•å¼€ä¸€ä¸ªè¢«å¹¿æ³›è®¨è®ºçš„è¯é¢˜ï¼ŒåŒ…æ‹¬è®¨è®ºçš„èƒŒæ™¯ã€å„æ–¹è§‚ç‚¹ã€äº‰è®®ç‚¹ä»¥åŠå¯¹æœªæ¥çš„å±•æœ›ã€‚] [Source: T5]
    *   **[æ™®ééœ€æ±‚B]**: [è¯¦ç»†æ€»ç»“ä¸€ä¸ªæ™®éå­˜åœ¨çš„éœ€æ±‚ï¼Œå¹¶åˆ†æè¯¥éœ€æ±‚äº§ç”Ÿçš„åŸå› å’Œç¤¾åŒºæå‡ºçš„æ½œåœ¨è§£å†³æ–¹æ¡ˆã€‚] [Source: T10]
    *   ...(å°½å¯èƒ½å¤šåœ°åˆ—å‡ºè¯é¢˜/éœ€æ±‚)

---

## ä¸‰ã€ä»·å€¼ä¿¡æ¯æŒ–æ˜

*   **é«˜ä»·å€¼èµ„æº/å·¥å…·**:
    *   **[èµ„æº/å·¥å…·A]**: [è¯¦ç»†ä»‹ç»è¯¥èµ„æº/å·¥å…·ï¼ŒåŒ…æ‹¬å…¶åç§°ã€åŠŸèƒ½ã€ä¼˜ç‚¹ä»¥åŠç¤¾åŒºæˆå‘˜åˆ†äº«çš„ä½¿ç”¨æŠ€å·§æˆ–ç»éªŒã€‚] [Source: T2]
    *   **[èµ„æº/å·¥å…·B]**: [åŒä¸Šã€‚] [Source: T8]
    *   ...(å°½å¯èƒ½å¤šåœ°åˆ—å‡ºèµ„æº/å·¥å…·)

*   **æœ‰è¶£è§‚ç‚¹/æ·±åº¦è®¨è®º**:
    *   **[å…³äº"XX"çš„è§‚ç‚¹]**: [è¯¦ç»†é˜è¿°ä¸€ä¸ªæœ‰å¯å‘æ€§çš„è§‚ç‚¹ï¼Œåˆ†æå…¶é‡è¦æ€§ï¼Œå¹¶æ€»ç»“å› æ­¤å¼•å‘çš„ç²¾å½©è®¨è®ºã€‚] [Source: T4]
    *   **[å…³äº"YY"çš„è®¨è®º]**: [åŒä¸Šã€‚] [Source: T6]
    *   ...(å°½å¯èƒ½å¤šåœ°åˆ—å‡ºè§‚ç‚¹/è®¨è®º)

---

## å››ã€è¡ŒåŠ¨å»ºè®®

*   **ç»™äº§å“ç»ç†çš„å»ºè®®**:
    *   [å»ºè®®1ï¼š[æå‡ºå…·ä½“å»ºè®®]ã€‚ç†ç”±ä¸é¢„æœŸæ•ˆæœï¼š[é˜è¿°è¯¥å»ºè®®çš„é€»è¾‘ä¾æ®ï¼Œä»¥åŠé‡‡çº³åå¯èƒ½å¸¦æ¥çš„å¥½å¤„]ã€‚] [Sources: T2, T9]
    *   [å»ºè®®2ï¼š...]

*   **ç»™åˆ›ä¸šè€…/æŠ•èµ„è€…çš„å»ºè®®**:
    *   [å»ºè®®1ï¼š[æå‡ºå…·ä½“å»ºè®®]ã€‚ç†ç”±ä¸é¢„æœŸæ•ˆæœï¼š[é˜è¿°è¯¥å»ºè®®çš„é€»è¾‘ä¾æ®ï¼Œä»¥åŠé‡‡çº³åå¯èƒ½å¸¦æ¥çš„å¥½å¤„]ã€‚] [Source: T1]
    *   [å»ºè®®2ï¼š...]

*   **ç»™æŠ€æœ¯ä»ä¸šè€…çš„å»ºè®®**:
    *   [å»ºè®®1ï¼š[æå‡ºå…·ä½“å»ºè®®]ã€‚ç†ç”±ä¸é¢„æœŸæ•ˆæœï¼š[é˜è¿°è¯¥å»ºè®®çš„é€»è¾‘ä¾æ®ï¼Œä»¥åŠé‡‡çº³åå¯èƒ½å¸¦æ¥çš„å¥½å¤„]ã€‚] [Source: T3]
    *   [å»ºè®®2ï¼š...]
"""

    def _prompt_weekly(self) -> str:
        return (
            "# Role: èµ„æ·±ç¤¾ç¾¤æˆ˜ç•¥é¡¾é—®\n"
            "\n"
            "# Context:\n"
            "ä½ å°†åŸºäºæœ€è¿‘7å¤©çš„ã€Šå³åˆ»24hçƒ­ç‚¹è¿½è¸ªå™¨ã€‹æ—¥æŠ¥æ±‡ç¼–ï¼ˆå·²æŒ‰æ—¶é—´é¡ºåºæ ‡è®°ä¸º D1...Dnï¼‰ã€‚æ¯ä»½æ—¥æŠ¥éƒ½å·²å®Œæˆå½“å¤©çš„ä¸»é¢˜æç‚¼ä¸æ¥æºå¼•ç”¨ï¼Œè¯·åœ¨ä½ çš„åˆ†æä¸­å¼•ç”¨è¿™äº›æ—¥æŠ¥ç¼–å·ï¼Œä¾‹å¦‚ `[Source: D3]` æˆ– `[Sources: D2, D6]`ã€‚ç›®æ ‡æ˜¯ä»è·¨æ—¥è§†è§’è¯†åˆ«è¶‹åŠ¿ã€ç»“æ„åŒ–æ´å¯Ÿï¼Œå¹¶è¾“å‡ºé«˜ä»·å€¼çš„å‘¨åº¦æˆ˜ç•¥å»ºè®®ã€‚\n"
            "\n"
            "# Core Principles:\n"
            "1. å¿…é¡»åœ¨æ¯ä¸ªç»“è®ºæˆ–å»ºè®®åæ³¨æ˜å¼•ç”¨çš„æ—¥æŠ¥ç¼–å·ï¼Œä¿æŒå¯è¿½æº¯æ€§ã€‚\n"
            "2. å¼ºè°ƒæ—¶é—´åºåˆ—ä¸Šçš„å˜åŒ–ã€åŠ¨å› ä¸æ½œåœ¨èµ°å‘ï¼Œè€Œä¸æ˜¯ç®€å•å †å æ¯æ—¥æ‘˜è¦ã€‚\n"
            "3. ä»æŠ€æœ¯/äº§å“/åˆ›ä¸š/æŠ•èµ„/è¡Œä¸š/æ–‡åŒ–ç­‰å¤šä¸ªè§†è§’è¯†åˆ«å±‚æ¬¡åŒ–æ´å¯Ÿï¼ŒæŒ‡å‡ºå„è§’è‰²çš„å…³æ³¨ç‚¹ã€‚\n"
            "4. è‹¥å‘ç°è¿ç»­å‡ æ—¥é‡å¤å‡ºç°çš„è®®é¢˜ï¼Œè¯·å½’çº³å…¶æ¼”è¿›è·¯å¾„ä¸èƒŒåé©±åŠ¨å› ç´ ã€‚\n"
            "\n"
            "# Input Materials (Daily Hotspot Reports D1...Dn):\n\n{content}\n\n"
            "# Your Task:\n"
            "è¯·è¾“å‡ºç»“æ„åŒ–Markdownå‘¨æŠ¥ï¼Œè‡³å°‘åŒ…å«ä»¥ä¸‹æ¨¡å—ï¼š\n"
            "## ä¸€ã€æ ¸å¿ƒä¸»é¢˜ä¸å…³æ³¨åº¦ (Top Themes)\n"
            "- å½’çº³3-5ä¸ªè·¨æ—¥æŒç»­å—åˆ°å…³æ³¨çš„ä¸»é¢˜ï¼Œè¯´æ˜æ¼”è¿›è„‰ç»œä¸å…³é”®ç»“è®ºã€‚[Sources: ...]\n"
            "\n"
            "## äºŒã€å…³é”®æ´å¯Ÿä¸è¶‹åŠ¿åˆ¤æ–­ (Insights & Trends)\n"
            "- æç‚¼æœ¬å‘¨å‡ºç°çš„æ˜¾è‘—å˜åŒ–ã€æ½œåœ¨é£é™©æˆ–æ–°æœºä¼šï¼Œåˆ†ææˆå› ä¸å½±å“é¢ã€‚[Sources: ...]\n"
            "- åˆ—ä¸¾å€¼å¾—è·Ÿè¿›çš„æŠ€æœ¯/äº§å“/å¸‚åœºä¿¡å·ï¼Œå¹¶è¯´æ˜å…¶çƒ­åº¦æ¼”è¿›ã€‚[Sources: ...]\n"
            "\n"
            "## ä¸‰ã€ç»“æ„åŒ–æ·±åº¦åˆ†æ (Deep Dive)\n"
            "- ä»ä¾›ç»™/éœ€æ±‚/ç”Ÿæ€/ç«äº‰æ ¼å±€ç­‰è§’åº¦å±•å¼€2-3ä¸ªæ·±åº¦ä¸“é¢˜ï¼Œè§£é‡Šå…¶æˆ˜ç•¥æ„ä¹‰ã€‚[Sources: ...]\n"
            "\n"
            "## å››ã€è§’è‰²å®šå‘è¡ŒåŠ¨å»ºè®® (Actionables)\n"
            "- åˆ†åˆ«ä¸ºäº§å“ç»ç†ã€æŠ€æœ¯ä»ä¸šè€…ã€åˆ›ä¸šè€…/æŠ•èµ„è€…æä¾›1-2æ¡å¯æ‰§è¡Œå»ºè®®ï¼Œè¯´æ˜å»ºè®®ä¾æ®ä¸é¢„æœŸæ”¶ç›Šã€‚[Sources: ...]\n"
        )

    # ---------- æŠ¥å‘Šç”Ÿæˆ ----------
    def _analyze_with_llm(self, content: str, prompt_template: str, model_override: Optional[str] = None) -> Optional[Dict[str, Any]]:
        """è°ƒç”¨æ™ºèƒ½æ¨¡å‹è¿›è¡Œæ·±åº¦åˆ†æï¼Œå¤±è´¥æ—¶è¿”å›None"""
        try:
            if llm_client is None:
                return None
            # æ ¼å¼åŒ–æç¤ºè¯
            prompt = prompt_template.format(content=content)
            # ä½¿ç”¨æ™ºèƒ½æ¨¡å‹è¿›è¡Œå¤æ‚æŠ¥å‘Šç”Ÿæˆä»»åŠ¡
            res = llm_client.call_smart_model(prompt, model_override=model_override)
            if isinstance(res, dict) and res.get('success'):
                return res
            return None
        except Exception as e:  # å…œåº•ï¼Œé¿å…å½±å“ä¸»æµç¨‹
            self.logger.warning(f"æ™ºèƒ½æ¨¡å‹åˆ†æå¤±è´¥ï¼Œå°†å›é€€æœ¬åœ°æŠ¥å‘Š: {e}")
            return None

    def _make_fallback_report(
        self,
        header: str,
        posts: List[Dict[str, Any]],
        period_start: datetime,
        period_end: datetime,
        sources: List[Dict[str, Any]],
    ) -> str:
        lines: List[str] = []
        lines.append(header)
        lines.append("")
        lines.append(f"æ—¶é—´èŒƒå›´ï¼š{period_start.strftime('%Y-%m-%d %H:%M')} - {period_end.strftime('%Y-%m-%d %H:%M')}")
        lines.append("")
        lines.append("LLMåˆ†æä¸å¯ç”¨ï¼Œä»¥ä¸‹ä¸ºåŸºäºç´ æçš„å ä½æŠ¥å‘Šï¼š")
        lines.append("")
        lines.append("## çƒ­é—¨åŠ¨æ€æ¸…å• (Top Materials)")
        for idx, p in enumerate(posts[:30], 1):
            title = p.get('title') or '(æ— æ ‡é¢˜)'
            link = p.get('link') or ''
            nickname = p.get('nickname') or p.get('jike_user_id') or 'æœªçŸ¥ä½œè€…'
            lines.append(f"{idx}. {title} - @{nickname}  {link}")
        lines.append("")
        lines.append(self._render_sources_section(sources))
        report_content = "\n".join(lines)

        # ä¸ºå ä½æŠ¥å‘Šä¹Ÿåº”ç”¨æ¥æºé“¾æ¥å¢å¼ºåå¤„ç†
        report_content = self._enhance_source_links(report_content, sources)

        return report_content

    async def _generate_light_report_for_model(
        self,
        *,
        model_name: str,
        display_name: str,
        posts: List[Dict[str, Any]],
        content_md: str,
        sources: List[Dict[str, Any]],
        prompt: str,
        start_time: datetime,
        end_time: datetime
    ) -> Dict[str, Any]:
        """åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­ç”ŸæˆæŒ‡å®šæ¨¡å‹çš„æ—¥æŠ¥èµ„è®¯"""
        return await asyncio.to_thread(
            self._generate_light_report_for_model_sync,
            model_name,
            display_name,
            posts,
            content_md,
            sources,
            prompt,
            start_time,
            end_time
        )

    def _generate_light_report_for_model_sync(
        self,
        model_name: str,
        display_name: str,
        posts: List[Dict[str, Any]],
        content_md: str,
        sources: List[Dict[str, Any]],
        prompt: str,
        start_time: datetime,
        end_time: datetime
    ) -> Dict[str, Any]:
        """åŒæ­¥æ‰§è¡ŒæŒ‡å®šæ¨¡å‹çš„æ—¥æŠ¥èµ„è®¯ç”Ÿæˆå’ŒNotionæ¨é€"""

        self.logger.info(f"[{display_name}] æ¨¡å‹çº¿ç¨‹å¯åŠ¨ï¼Œå¼€å§‹ç”Ÿæˆæ—¥æŠ¥èµ„è®¯")

        llm_analysis_result = self._analyze_with_llm(content_md, prompt, model_override=model_name)

        if not llm_analysis_result:
            error_msg = "LLMåˆ†æå¤±è´¥ï¼Œæœªç”Ÿæˆæ—¥æŠ¥èµ„è®¯"
            self.logger.warning(f"[{display_name}] {error_msg}")
            return {
                'success': False,
                'error': error_msg,
                'model': model_name,
                'model_display': display_name,
                'report_type': 'light'
            }

        llm_output = llm_analysis_result.get('content', '')
        beijing_time = self._bj_time()
        header_info = [
            f"# ğŸ“‹ å³åˆ»æ—¥æŠ¥èµ„è®¯ - {display_name}",
            "",
            f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {beijing_time.strftime('%Y-%m-%d %H:%M:%S')}*  ",
            "",
            f"*æ•°æ®èŒƒå›´: {start_time.strftime('%Y-%m-%d %H:%M:%S')} - {end_time.strftime('%Y-%m-%d %H:%M:%S')}*  ",
            "",
            f"*åˆ†æåŠ¨æ€æ•°: {len(posts)} æ¡*",
            "",
            "---",
            ""
        ]

        cleaned_llm_output = self._clean_llm_output_for_notion(llm_output)
        sources_section = self._render_sources_section(sources)

        footer_lines = ["", "---", ""]
        provider = llm_analysis_result.get('provider')
        model = llm_analysis_result.get('model')
        if provider:
            footer_lines.append(f"*åˆ†æå¼•æ“: {provider} ({model or 'unknown'})*")

        footer_lines.extend([
            "",
            f"ğŸ“Š **ç»Ÿè®¡æ‘˜è¦**: æœ¬æŠ¥å‘Šåˆ†æäº† {len(posts)} æ¡åŠ¨æ€",
            "",
            "*æœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒ*"
        ])
        footer_section = "\n".join(footer_lines)

        report_content = "\n".join(header_info) + cleaned_llm_output + "\n\n" + sources_section + footer_section
        report_content = self._enhance_source_links(report_content, sources)

        title = f"å³åˆ»æ—¥æŠ¥èµ„è®¯ - {display_name} - {end_time.strftime('%Y-%m-%d %H:%M')}"
        report_row = {
            'report_type': 'daily_light',
            'scope': 'global',
            'analysis_period_start': start_time,
            'analysis_period_end': end_time,
            'items_analyzed': len(posts),
            'report_title': title,
            'report_content': report_content,
        }
        report_id = self.db.save_report(report_row)

        model_report = {
            'model': model_name,
            'model_display': display_name,
            'success': True,
            'report_id': report_id,
            'report_title': title,
            'report_content': report_content,
            'provider': llm_analysis_result.get('provider') if llm_analysis_result else None,
            'items_analyzed': len(posts)
        }

        # å°è¯•æ¨é€åˆ°Notion
        notion_push_info = None
        try:
            from .notion_client import jike_notion_client

            beijing_time = self._bj_time()
            time_str = beijing_time.strftime('%H:%M')
            notion_title = f"[{time_str}] [{display_name}] å³åˆ»æ—¥æŠ¥èµ„è®¯ ({len(posts)}æ¡)"

            self.logger.info(f"å¼€å§‹æ¨é€æ—¥æŠ¥èµ„è®¯åˆ°Notion ({display_name}): {notion_title}")

            notion_result = jike_notion_client.create_report_page_in_hierarchy(
                report_title=notion_title,
                report_content=report_content,
                report_date=beijing_time,
                report_type='light'
            )

            if notion_result.get('success'):
                self.logger.info(f"æ—¥æŠ¥èµ„è®¯æˆåŠŸæ¨é€åˆ°Notion ({display_name}): {notion_result.get('page_url')}")
                notion_push_info = {
                    'success': True,
                    'page_url': notion_result.get('page_url'),
                    'path': notion_result.get('path')
                }
            else:
                error_msg = notion_result.get('error', 'æœªçŸ¥é”™è¯¯')
                self.logger.warning(f"æ¨é€æ—¥æŠ¥èµ„è®¯åˆ°Notionå¤±è´¥ ({display_name}): {error_msg}")
                notion_push_info = {
                    'success': False,
                    'error': error_msg
                }

        except Exception as e:
            self.logger.warning(f"æ¨é€æ—¥æŠ¥èµ„è®¯åˆ°Notionæ—¶å‡ºé”™ ({display_name}): {e}")
            notion_push_info = {
                'success': False,
                'error': str(e)
            }

        if notion_push_info:
            model_report['notion_push'] = notion_push_info

        return model_report

    async def generate_light_reports(self, hours_back: Optional[int] = None) -> Dict[str, Any]:
        """ç”Ÿæˆæ—¥æŠ¥èµ„è®¯ï¼ˆLight Reportï¼‰ï¼Œå¤šæ¨¡å‹å¹¶è¡Œæ‰§è¡Œ

        ä½¿ç”¨lightä¸Šä¸‹æ–‡æ¨¡å¼ï¼Œé™ä½æˆæœ¬
        """
        hours = int(hours_back or self.analysis_cfg.get('hours_back_daily', 24))
        end_time = self._bj_time()
        start_time = end_time - timedelta(hours=hours)

        posts = self.db.get_recent_posts(hours_back=hours)
        if not posts:
            return {
                'success': False,
                'error': f'æœ€è¿‘{hours}å°æ—¶å†…æ— æ–°å¢åŠ¨æ€',
                'report_type': 'light'
            }

        # è®¾ç½®ä¸ºlightæ¨¡å¼
        original_mode = self.context_mode
        self.context_mode = 'light'

        content_md, sources = self._format_posts_for_llm(posts, source_prefix='T')
        prompt = self._prompt_daily_briefing()

        # æ¢å¤åŸå§‹æ¨¡å¼
        self.context_mode = original_mode

        models_to_generate = self._get_report_models()
        if not models_to_generate:
            self.logger.warning("æœªé…ç½®ä»»ä½•å¯ç”¨äºç”ŸæˆæŠ¥å‘Šçš„æ¨¡å‹")
            return {
                'success': False,
                'error': 'æœªé…ç½®å¯ç”¨çš„LLMæ¨¡å‹',
                'items_analyzed': 0,
                'report_type': 'light'
            }

        model_reports: List[Dict[str, Any]] = []
        failures: List[Dict[str, Any]] = []
        tasks = []
        task_meta: List[Dict[str, str]] = []

        for model_name in models_to_generate:
            display_name = self._get_model_display_name(model_name)
            task_meta.append({'model': model_name, 'display': display_name})
            tasks.append(
                self._generate_light_report_for_model(
                    model_name=model_name,
                    display_name=display_name,
                    posts=posts,
                    content_md=content_md,
                    sources=sources,
                    prompt=prompt,
                    start_time=start_time,
                    end_time=end_time
                )
            )

        self.logger.info(
            f"å¼€å§‹å¹¶è¡Œç”Ÿæˆ {len(tasks)} ä»½æ—¥æŠ¥èµ„è®¯: {[meta['display'] for meta in task_meta]}"
        )

        task_results = await asyncio.gather(*tasks, return_exceptions=True)

        for meta, task_result in zip(task_meta, task_results):
            model_name = meta['model']
            display_name = meta['display']

            if isinstance(task_result, Exception):
                error_msg = str(task_result)
                self.logger.warning(
                    f"æ¨¡å‹ {model_name} ({display_name}) æ—¥æŠ¥èµ„è®¯ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°æœªå¤„ç†å¼‚å¸¸: {error_msg}"
                )
                failures.append({
                    'model': model_name,
                    'model_display': display_name,
                    'error': error_msg
                })
                continue

            if task_result.get('success'):
                model_reports.append(task_result)
            else:
                failure_entry = {
                    'model': model_name,
                    'model_display': display_name,
                    'error': task_result.get('error', 'æŠ¥å‘Šç”Ÿæˆå¤±è´¥')
                }
                failures.append(failure_entry)

        overall_success = len(model_reports) > 0
        result = {
            'success': overall_success,
            'items_analyzed': len(posts) if overall_success else 0,
            'model_reports': model_reports,
            'failures': failures,
            'report_type': 'light'
        }

        if overall_success:
            primary_report = model_reports[0]
            result['report_id'] = primary_report['report_id']
            result['title'] = primary_report['report_title']
            result['notion_push'] = primary_report.get('notion_push')
            result['report_ids'] = [mr['report_id'] for mr in model_reports]

        self.logger.info(
            f"æ—¥æŠ¥èµ„è®¯ç”Ÿæˆå®Œæˆ: æˆåŠŸç”Ÿæˆ {len(model_reports)} ä»½æŠ¥å‘Šï¼Œå¤±è´¥ {len(failures)} ä»½"
        )

        return result

    async def _generate_deep_report_for_model(
        self,
        *,
        model_name: str,
        display_name: str,
        posts: List[Dict[str, Any]],
        content_md: str,
        sources: List[Dict[str, Any]],
        prompt: str,
        start_time: datetime,
        end_time: datetime
    ) -> Dict[str, Any]:
        """åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­ç”ŸæˆæŒ‡å®šæ¨¡å‹çš„æ·±åº¦æ´å¯ŸæŠ¥å‘Š"""
        return await asyncio.to_thread(
            self._generate_deep_report_for_model_sync,
            model_name,
            display_name,
            posts,
            content_md,
            sources,
            prompt,
            start_time,
            end_time
        )

    def _generate_deep_report_for_model_sync(
        self,
        model_name: str,
        display_name: str,
        posts: List[Dict[str, Any]],
        content_md: str,
        sources: List[Dict[str, Any]],
        prompt: str,
        start_time: datetime,
        end_time: datetime
    ) -> Dict[str, Any]:
        """åŒæ­¥æ‰§è¡ŒæŒ‡å®šæ¨¡å‹çš„æ·±åº¦æ´å¯ŸæŠ¥å‘Šç”Ÿæˆå’ŒNotionæ¨é€"""

        self.logger.info(f"[{display_name}] æ¨¡å‹çº¿ç¨‹å¯åŠ¨ï¼Œå¼€å§‹ç”Ÿæˆæ·±åº¦æ´å¯ŸæŠ¥å‘Š")

        llm_analysis_result = self._analyze_with_llm(content_md, prompt, model_override=model_name)

        if not llm_analysis_result:
            error_msg = "LLMåˆ†æå¤±è´¥ï¼Œæœªç”Ÿæˆæ·±åº¦æ´å¯Ÿ"
            self.logger.warning(f"[{display_name}] {error_msg}")
            return {
                'success': False,
                'error': error_msg,
                'model': model_name,
                'model_display': display_name,
                'report_type': 'deep'
            }

        llm_output = llm_analysis_result.get('content', '')
        beijing_time = self._bj_time()
        header_info = [
            f"# ğŸ“Š å³åˆ»æ·±åº¦æ´å¯Ÿ - {display_name}",
            "",
            f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {beijing_time.strftime('%Y-%m-%d %H:%M:%S')}*  ",
            "",
            f"*æ•°æ®èŒƒå›´: {start_time.strftime('%Y-%m-%d %H:%M:%S')} - {end_time.strftime('%Y-%m-%d %H:%M:%S')}*  ",
            "",
            f"*åˆ†æåŠ¨æ€æ•°: {len(posts)} æ¡*",
            "",
            "---",
            ""
        ]

        cleaned_llm_output = self._clean_llm_output_for_notion(llm_output)
        sources_section = self._render_sources_section(sources)

        footer_lines = ["", "---", ""]
        provider = llm_analysis_result.get('provider')
        model = llm_analysis_result.get('model')
        if provider:
            footer_lines.append(f"*åˆ†æå¼•æ“: {provider} ({model or 'unknown'})*")

        footer_lines.extend([
            "",
            f"ğŸ“Š **ç»Ÿè®¡æ‘˜è¦**: æœ¬æŠ¥å‘Šåˆ†æäº† {len(posts)} æ¡åŠ¨æ€",
            "",
            "*æœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒ*"
        ])
        footer_section = "\n".join(footer_lines)

        report_content = "\n".join(header_info) + cleaned_llm_output + "\n\n" + sources_section + footer_section
        report_content = self._enhance_source_links(report_content, sources)

        title = f"å³åˆ»æ·±åº¦æ´å¯Ÿ - {display_name} - {end_time.strftime('%Y-%m-%d %H:%M')}"
        report_row = {
            'report_type': 'daily_deep',
            'scope': 'global',
            'analysis_period_start': start_time,
            'analysis_period_end': end_time,
            'items_analyzed': len(posts),
            'report_title': title,
            'report_content': report_content,
        }
        report_id = self.db.save_report(report_row)

        model_report = {
            'model': model_name,
            'model_display': display_name,
            'success': True,
            'report_id': report_id,
            'report_title': title,
            'report_content': report_content,
            'provider': llm_analysis_result.get('provider') if llm_analysis_result else None,
            'items_analyzed': len(posts)
        }

        # å°è¯•æ¨é€åˆ°Notion
        notion_push_info = None
        try:
            from .notion_client import jike_notion_client

            beijing_time = self._bj_time()
            time_str = beijing_time.strftime('%H:%M')
            notion_title = f"[{time_str}] [{display_name}] å³åˆ»æ·±åº¦æ´å¯Ÿ ({len(posts)}æ¡)"

            self.logger.info(f"å¼€å§‹æ¨é€æ·±åº¦æ´å¯Ÿåˆ°Notion ({display_name}): {notion_title}")

            notion_result = jike_notion_client.create_report_page_in_hierarchy(
                report_title=notion_title,
                report_content=report_content,
                report_date=beijing_time,
                report_type='deep'
            )

            if notion_result.get('success'):
                self.logger.info(f"æ·±åº¦æ´å¯ŸæˆåŠŸæ¨é€åˆ°Notion ({display_name}): {notion_result.get('page_url')}")
                notion_push_info = {
                    'success': True,
                    'page_url': notion_result.get('page_url'),
                    'path': notion_result.get('path')
                }
            else:
                error_msg = notion_result.get('error', 'æœªçŸ¥é”™è¯¯')
                self.logger.warning(f"æ¨é€æ·±åº¦æ´å¯Ÿåˆ°Notionå¤±è´¥ ({display_name}): {error_msg}")
                notion_push_info = {
                    'success': False,
                    'error': error_msg
                }

        except Exception as e:
            self.logger.warning(f"æ¨é€æ·±åº¦æ´å¯Ÿåˆ°Notionæ—¶å‡ºé”™ ({display_name}): {e}")
            notion_push_info = {
                'success': False,
                'error': str(e)
            }

        if notion_push_info:
            model_report['notion_push'] = notion_push_info

        return model_report

    async def generate_deep_reports(self, hours_back: Optional[int] = None) -> Dict[str, Any]:
        """ç”Ÿæˆæ·±åº¦æ´å¯ŸæŠ¥å‘Šï¼ˆDeep Reportï¼‰ï¼Œå¤šæ¨¡å‹å¹¶è¡Œæ‰§è¡Œ

        ä½¿ç”¨fullä¸Šä¸‹æ–‡æ¨¡å¼ï¼Œä¿è¯æ·±åº¦åˆ†æ
        """
        hours = int(hours_back or self.analysis_cfg.get('hours_back_daily', 24))
        end_time = self._bj_time()
        start_time = end_time - timedelta(hours=hours)

        posts = self.db.get_recent_posts(hours_back=hours)
        if not posts:
            return {
                'success': False,
                'error': f'æœ€è¿‘{hours}å°æ—¶å†…æ— æ–°å¢åŠ¨æ€',
                'report_type': 'deep'
            }

        # è®¾ç½®ä¸ºfullæ¨¡å¼
        original_mode = self.context_mode
        self.context_mode = 'full'

        content_md, sources = self._format_posts_for_llm(posts, source_prefix='T')
        prompt = self._prompt_daily()

        # æ¢å¤åŸå§‹æ¨¡å¼
        self.context_mode = original_mode

        models_to_generate = self._get_report_models()
        if not models_to_generate:
            self.logger.warning("æœªé…ç½®ä»»ä½•å¯ç”¨äºç”ŸæˆæŠ¥å‘Šçš„æ¨¡å‹")
            return {
                'success': False,
                'error': 'æœªé…ç½®å¯ç”¨çš„LLMæ¨¡å‹',
                'items_analyzed': 0,
                'report_type': 'deep'
            }

        model_reports: List[Dict[str, Any]] = []
        failures: List[Dict[str, Any]] = []
        tasks = []
        task_meta: List[Dict[str, str]] = []

        for model_name in models_to_generate:
            display_name = self._get_model_display_name(model_name)
            task_meta.append({'model': model_name, 'display': display_name})
            tasks.append(
                self._generate_deep_report_for_model(
                    model_name=model_name,
                    display_name=display_name,
                    posts=posts,
                    content_md=content_md,
                    sources=sources,
                    prompt=prompt,
                    start_time=start_time,
                    end_time=end_time
                )
            )

        self.logger.info(
            f"å¼€å§‹å¹¶è¡Œç”Ÿæˆ {len(tasks)} ä»½æ·±åº¦æ´å¯Ÿ: {[meta['display'] for meta in task_meta]}"
        )

        task_results = await asyncio.gather(*tasks, return_exceptions=True)

        for meta, task_result in zip(task_meta, task_results):
            model_name = meta['model']
            display_name = meta['display']

            if isinstance(task_result, Exception):
                error_msg = str(task_result)
                self.logger.warning(
                    f"æ¨¡å‹ {model_name} ({display_name}) æ·±åº¦æ´å¯Ÿç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°æœªå¤„ç†å¼‚å¸¸: {error_msg}"
                )
                failures.append({
                    'model': model_name,
                    'model_display': display_name,
                    'error': error_msg
                })
                continue

            if task_result.get('success'):
                model_reports.append(task_result)
            else:
                failure_entry = {
                    'model': model_name,
                    'model_display': display_name,
                    'error': task_result.get('error', 'æŠ¥å‘Šç”Ÿæˆå¤±è´¥')
                }
                failures.append(failure_entry)

        overall_success = len(model_reports) > 0
        result = {
            'success': overall_success,
            'items_analyzed': len(posts) if overall_success else 0,
            'model_reports': model_reports,
            'failures': failures,
            'report_type': 'deep'
        }

        if overall_success:
            primary_report = model_reports[0]
            result['report_id'] = primary_report['report_id']
            result['title'] = primary_report['report_title']
            result['notion_push'] = primary_report.get('notion_push')
            result['report_ids'] = [mr['report_id'] for mr in model_reports]

        self.logger.info(
            f"æ·±åº¦æ´å¯Ÿç”Ÿæˆå®Œæˆ: æˆåŠŸç”Ÿæˆ {len(model_reports)} ä»½æŠ¥å‘Šï¼Œå¤±è´¥ {len(failures)} ä»½"
        )

        return result

    async def run_dual_report_generation(self, hours_back: Optional[int] = None) -> Dict[str, Any]:
        """è¿è¡ŒåŒè½¨åˆ¶æŠ¥å‘Šç”Ÿæˆæµç¨‹ï¼ˆæ€»è°ƒåº¦æ–¹æ³•ï¼‰

        é˜¶æ®µ1: ç”Ÿæˆæ‰€æœ‰æ—¥æŠ¥èµ„è®¯
        é˜¶æ®µ2: ç”Ÿæˆæ‰€æœ‰æ·±åº¦æ´å¯Ÿ
        """
        self.logger.info("å¼€å§‹æ‰§è¡ŒåŒè½¨åˆ¶æŠ¥å‘Šç”Ÿæˆæµç¨‹")

        # é˜¶æ®µ1: æ—¥æŠ¥èµ„è®¯ï¼ˆä½¿ç”¨lightæ¨¡å¼ï¼‰
        self.logger.info("===== é˜¶æ®µ1: ç”Ÿæˆæ—¥æŠ¥èµ„è®¯ =====")
        light_result = await self.generate_light_reports(hours_back=hours_back)

        # é˜¶æ®µ2: æ·±åº¦æ´å¯Ÿï¼ˆä½¿ç”¨fullæ¨¡å¼ï¼‰
        self.logger.info("===== é˜¶æ®µ2: ç”Ÿæˆæ·±åº¦æ´å¯Ÿ =====")
        deep_result = await self.generate_deep_reports(hours_back=hours_back)

        # æ±‡æ€»ç»Ÿè®¡
        light_success_count = len(light_result.get('model_reports', []))
        deep_success_count = len(deep_result.get('model_reports', []))
        total_success = light_success_count + deep_success_count

        light_fail_count = len(light_result.get('failures', []))
        deep_fail_count = len(deep_result.get('failures', []))
        total_fail = light_fail_count + deep_fail_count

        overall_success = total_success > 0

        result = {
            'success': overall_success,
            'light_reports': light_result,
            'deep_reports': deep_result,
            'items_analyzed': light_result.get('items_analyzed', 0),
            'light_reports_count': light_success_count,
            'deep_reports_count': deep_success_count,
            'total_reports_count': total_success,
            'message': f"åŒè½¨åˆ¶æŠ¥å‘Šç”Ÿæˆå®Œæˆ: æ—¥æŠ¥èµ„è®¯ {light_success_count} ä»½ï¼Œæ·±åº¦æ´å¯Ÿ {deep_success_count} ä»½ï¼Œå¤±è´¥ {total_fail} ä»½"
        }

        self.logger.info(result['message'])

        return result

    async def generate_daily_hotspot(self, hours_back: Optional[int] = None) -> Dict[str, Any]:
        hours = int(hours_back or self.analysis_cfg.get('hours_back_daily', 24))
        end_time = self._bj_time()
        start_time = end_time - timedelta(hours=hours)

        posts = self.db.get_recent_posts(hours_back=hours)
        if not posts:
            return {
                'success': False,
                'error': f'æœ€è¿‘{hours}å°æ—¶å†…æ— æ–°å¢åŠ¨æ€',
            }

        content_md, sources = self._format_posts_for_llm(posts, source_prefix='T')
        prompt = self._prompt_daily()

        # è·å–è¦ä½¿ç”¨çš„æ¨¡å‹åˆ—è¡¨
        models_to_generate = self._get_report_models()
        if not models_to_generate:
            self.logger.warning("æœªé…ç½®ä»»ä½•å¯ç”¨äºç”ŸæˆæŠ¥å‘Šçš„æ¨¡å‹")
            return {
                'success': False,
                'error': 'æœªé…ç½®å¯ç”¨çš„LLMæ¨¡å‹',
                'items_analyzed': 0
            }

        model_reports: List[Dict[str, Any]] = []
        failures: List[Dict[str, Any]] = []
        tasks = []
        task_meta: List[Dict[str, str]] = []

        # ä¸ºæ¯ä¸ªæ¨¡å‹åˆ›å»ºå¹¶è¡Œä»»åŠ¡
        for model_name in models_to_generate:
            display_name = self._get_model_display_name(model_name)
            task_meta.append({'model': model_name, 'display': display_name})
            tasks.append(
                self._generate_daily_report_for_model(
                    model_name=model_name,
                    display_name=display_name,
                    posts=posts,
                    content_md=content_md,
                    sources=sources,
                    prompt=prompt,
                    start_time=start_time,
                    end_time=end_time
                )
            )

        self.logger.info(
            f"å¼€å§‹å¹¶è¡Œç”Ÿæˆ {len(tasks)} ä»½æ—¥æŠ¥: {[meta['display'] for meta in task_meta]}"
        )

        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        task_results = await asyncio.gather(*tasks, return_exceptions=True)

        # å¤„ç†ä»»åŠ¡ç»“æœ
        for meta, task_result in zip(task_meta, task_results):
            model_name = meta['model']
            display_name = meta['display']

            if isinstance(task_result, Exception):
                error_msg = str(task_result)
                self.logger.warning(
                    f"æ¨¡å‹ {model_name} ({display_name}) æ—¥æŠ¥ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°æœªå¤„ç†å¼‚å¸¸: {error_msg}"
                )
                failures.append({
                    'model': model_name,
                    'model_display': display_name,
                    'error': error_msg
                })
                continue

            if task_result.get('success'):
                model_reports.append(task_result)
            else:
                failure_entry = {
                    'model': model_name,
                    'model_display': display_name,
                    'error': task_result.get('error', 'æŠ¥å‘Šç”Ÿæˆå¤±è´¥')
                }
                failures.append(failure_entry)

        # æ„å»ºæœ€ç»ˆç»“æœ
        overall_success = len(model_reports) > 0
        result = {
            'success': overall_success,
            'items_analyzed': len(posts) if overall_success else 0,
            'model_reports': model_reports,
            'failures': failures
        }

        if overall_success:
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªæˆåŠŸçš„æŠ¥å‘Šä½œä¸ºä¸»è¦ç»“æœ
            primary_report = model_reports[0]
            result['report_id'] = primary_report['report_id']
            result['title'] = primary_report['report_title']
            result['notion_push'] = primary_report.get('notion_push')
            result['report_ids'] = [mr['report_id'] for mr in model_reports]

        self.logger.info(
            f"æ—¥æŠ¥ç”Ÿæˆå®Œæˆ: æˆåŠŸç”Ÿæˆ {len(model_reports)} ä»½æŠ¥å‘Šï¼Œå¤±è´¥ {len(failures)} ä»½"
        )

        return result

    async def generate_weekly_digest(self, days_back: Optional[int] = None) -> Dict[str, Any]:
        days = int(days_back or self.analysis_cfg.get('days_back_weekly', 7))
        daily_reports = self.db.get_recent_daily_reports(days=days)
        if not daily_reports:
            return {'success': False, 'error': f'æœ€è¿‘{days}å¤©å†…æ— å¯ç”¨æ—¥æŠ¥'}

        content_md, sources = self._format_daily_reports_for_weekly(daily_reports)
        if not content_md:
            return {'success': False, 'error': 'å‘¨æŠ¥è¾“å…¥å†…å®¹ä¸ºç©º'}

        items_analyzed_total = sum((r.get('items_analyzed') or 0) for r in daily_reports)

        start_candidates = [r.get('analysis_period_start') for r in daily_reports if isinstance(r.get('analysis_period_start'), datetime)]
        end_candidates = [r.get('analysis_period_end') for r in daily_reports if isinstance(r.get('analysis_period_end'), datetime)]

        if start_candidates:
            start_time = min(start_candidates)
        else:
            start_time = self._bj_time() - timedelta(days=days)

        if end_candidates:
            end_time = max(end_candidates)
        else:
            end_time = self._bj_time()

        # è·å–è¦ä½¿ç”¨çš„æ¨¡å‹åˆ—è¡¨
        models_to_generate = self._get_report_models()
        if not models_to_generate:
            self.logger.warning("æœªé…ç½®ä»»ä½•å¯ç”¨äºç”ŸæˆæŠ¥å‘Šçš„æ¨¡å‹")
            return {
                'success': False,
                'error': 'æœªé…ç½®å¯ç”¨çš„LLMæ¨¡å‹',
                'items_analyzed': 0
            }

        model_reports: List[Dict[str, Any]] = []
        failures: List[Dict[str, Any]] = []

        # ä¸ºæ¯ä¸ªæ¨¡å‹åˆ›å»ºå¹¶è¡Œä»»åŠ¡
        tasks = []
        task_meta: List[Dict[str, str]] = []

        for model_name in models_to_generate:
            display_name = self._get_model_display_name(model_name)
            task_meta.append({'model': model_name, 'display': display_name})
            tasks.append(
                self._generate_weekly_report_for_model(
                    model_name=model_name,
                    display_name=display_name,
                    daily_reports=daily_reports,
                    content_md=content_md,
                    sources=sources,
                    start_time=start_time,
                    end_time=end_time,
                    items_analyzed=items_analyzed_total
                )
            )

        self.logger.info(
            f"å¼€å§‹å¹¶è¡Œç”Ÿæˆ {len(tasks)} ä»½å‘¨æŠ¥: {[meta['display'] for meta in task_meta]}"
        )

        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        task_results = await asyncio.gather(*tasks, return_exceptions=True)

        # å¤„ç†ä»»åŠ¡ç»“æœ
        for meta, task_result in zip(task_meta, task_results):
            model_name = meta['model']
            display_name = meta['display']

            if isinstance(task_result, Exception):
                error_msg = str(task_result)
                self.logger.warning(
                    f"æ¨¡å‹ {model_name} ({display_name}) å‘¨æŠ¥ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°æœªå¤„ç†å¼‚å¸¸: {error_msg}"
                )
                failures.append({
                    'model': model_name,
                    'model_display': display_name,
                    'error': error_msg
                })
                continue

            if task_result.get('success'):
                model_reports.append(task_result)
            else:
                failure_entry = {
                    'model': model_name,
                    'model_display': display_name,
                    'error': task_result.get('error', 'æŠ¥å‘Šç”Ÿæˆå¤±è´¥')
                }
                failures.append(failure_entry)

        # æ„å»ºæœ€ç»ˆç»“æœ
        overall_success = len(model_reports) > 0
        result = {
            'success': overall_success,
            'items_analyzed': items_analyzed_total if overall_success else 0,
            'model_reports': model_reports,
            'failures': failures
        }

        if overall_success:
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªæˆåŠŸçš„æŠ¥å‘Šä½œä¸ºä¸»è¦ç»“æœ
            primary_report = model_reports[0]
            result['report_id'] = primary_report['report_id']
            result['title'] = primary_report['report_title']
            result['notion_push'] = primary_report.get('notion_push')
            result['report_ids'] = [mr['report_id'] for mr in model_reports]

        return result

    async def generate_quarterly_narrative(self, days_back: Optional[int] = None) -> Dict[str, Any]:
        days = int(days_back or self.analysis_cfg.get('days_back_quarterly', 90))
        end_time = self._bj_time()
        start_time = end_time - timedelta(days=days)

        posts = self.db.get_posts_for_analysis(days=days)
        if not posts:
            return {'success': False, 'error': f'æœ€è¿‘{days}å¤©å†…æ— åŠ¨æ€å¯åˆ†æ'}

        # å¤ç”¨å‘¨æŠ¥æç¤ºè¯ï¼Œå®é™…å¯æ›´å¤æ‚
        content_md, sources = self._format_posts_for_llm(posts, source_prefix='T')

        # è·å–è¦ä½¿ç”¨çš„æ¨¡å‹åˆ—è¡¨
        models_to_generate = self._get_report_models()
        if not models_to_generate:
            self.logger.warning("æœªé…ç½®ä»»ä½•å¯ç”¨äºç”ŸæˆæŠ¥å‘Šçš„æ¨¡å‹")
            return {
                'success': False,
                'error': 'æœªé…ç½®å¯ç”¨çš„LLMæ¨¡å‹',
                'items_analyzed': 0
            }

        model_reports: List[Dict[str, Any]] = []
        failures: List[Dict[str, Any]] = []
        tasks = []
        task_meta: List[Dict[str, str]] = []

        # ä¸ºæ¯ä¸ªæ¨¡å‹åˆ›å»ºå¹¶è¡Œä»»åŠ¡
        for model_name in models_to_generate:
            display_name = self._get_model_display_name(model_name)
            task_meta.append({'model': model_name, 'display': display_name})
            tasks.append(
                self._generate_quarterly_report_for_model(
                    model_name=model_name,
                    display_name=display_name,
                    posts=posts,
                    content_md=content_md,
                    sources=sources,
                    start_time=start_time,
                    end_time=end_time
                )
            )

        self.logger.info(
            f"å¼€å§‹å¹¶è¡Œç”Ÿæˆ {len(tasks)} ä»½å­£æŠ¥: {[meta['display'] for meta in task_meta]}"
        )

        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        task_results = await asyncio.gather(*tasks, return_exceptions=True)

        # å¤„ç†ä»»åŠ¡ç»“æœ
        for meta, task_result in zip(task_meta, task_results):
            model_name = meta['model']
            display_name = meta['display']

            if isinstance(task_result, Exception):
                error_msg = str(task_result)
                self.logger.warning(
                    f"æ¨¡å‹ {model_name} ({display_name}) å­£æŠ¥ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°æœªå¤„ç†å¼‚å¸¸: {error_msg}"
                )
                failures.append({
                    'model': model_name,
                    'model_display': display_name,
                    'error': error_msg
                })
                continue

            if task_result.get('success'):
                model_reports.append(task_result)
            else:
                failure_entry = {
                    'model': model_name,
                    'model_display': display_name,
                    'error': task_result.get('error', 'æŠ¥å‘Šç”Ÿæˆå¤±è´¥')
                }
                failures.append(failure_entry)

        # æ„å»ºæœ€ç»ˆç»“æœ
        overall_success = len(model_reports) > 0
        result = {
            'success': overall_success,
            'items_analyzed': len(posts) if overall_success else 0,
            'model_reports': model_reports,
            'failures': failures
        }

        if overall_success:
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªæˆåŠŸçš„æŠ¥å‘Šä½œä¸ºä¸»è¦ç»“æœ
            primary_report = model_reports[0]
            result['report_id'] = primary_report['report_id']
            result['title'] = primary_report['report_title']
            result['notion_push'] = primary_report.get('notion_push')
            result['report_ids'] = [mr['report_id'] for mr in model_reports]

        self.logger.info(
            f"å­£æŠ¥ç”Ÿæˆå®Œæˆ: æˆåŠŸç”Ÿæˆ {len(model_reports)} ä»½æŠ¥å‘Šï¼Œå¤±è´¥ {len(failures)} ä»½"
        )

        return result

    async def _generate_quarterly_report_for_model(
        self,
        *,
        model_name: str,
        display_name: str,
        posts: List[Dict[str, Any]],
        content_md: str,
        sources: List[Dict[str, Any]],
        start_time: datetime,
        end_time: datetime
    ) -> Dict[str, Any]:
        """åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­ç”ŸæˆæŒ‡å®šæ¨¡å‹çš„å­£æŠ¥"""
        return await asyncio.to_thread(
            self._generate_quarterly_report_for_model_sync,
            model_name,
            display_name,
            posts,
            content_md,
            sources,
            start_time,
            end_time
        )

    def _generate_quarterly_report_for_model_sync(
        self,
        model_name: str,
        display_name: str,
        posts: List[Dict[str, Any]],
        content_md: str,
        sources: List[Dict[str, Any]],
        start_time: datetime,
        end_time: datetime
    ) -> Dict[str, Any]:
        """åŒæ­¥æ‰§è¡ŒæŒ‡å®šæ¨¡å‹çš„å­£æŠ¥ç”Ÿæˆå’ŒNotionæ¨é€"""

        self.logger.info(f"[{display_name}] æ¨¡å‹çº¿ç¨‹å¯åŠ¨ï¼Œå¼€å§‹ç”Ÿæˆå­£æŠ¥")

        llm_analysis_result = self._analyze_with_llm(content_md, self._prompt_weekly(), model_override=model_name)

        if not llm_analysis_result:
            error_msg = "LLMåˆ†æå¤±è´¥ï¼Œæœªç”Ÿæˆå­£åº¦æŠ¥å‘Š"
            self.logger.warning(f"[{display_name}] {error_msg}")
            return {
                'success': False,
                'error': error_msg,
                'model': model_name,
                'model_display': display_name
            }

        llm_output = llm_analysis_result.get('content', '')
        # ä¸ºLLMç”Ÿæˆçš„æŠ¥å‘Šæ·»åŠ æ ‡å‡†å¤´éƒ¨ä¿¡æ¯
        beijing_time = self._bj_time()
        q = (end_time.month - 1) // 3 + 1
        header_info = [
            f"# ğŸš€ å³åˆ»å­£åº¦æˆ˜ç•¥å™äº‹ - {display_name} - {end_time.year} Q{q}",
            "",
            f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {beijing_time.strftime('%Y-%m-%d %H:%M:%S')}*  ",
            "",
            f"*æ•°æ®èŒƒå›´: {start_time.strftime('%Y-%m-%d %H:%M:%S')} - {end_time.strftime('%Y-%m-%d %H:%M:%S')}*  ",
            "",
            f"*åˆ†æåŠ¨æ€æ•°: {len(posts)} æ¡*",
            "",
            "---",
            ""
        ]

        # æ¸…ç†LLMè¾“å‡ºä¸­å¯èƒ½çš„æ ¼å¼é—®é¢˜
        cleaned_llm_output = self._clean_llm_output_for_notion(llm_output)

        sources_section = self._render_sources_section(sources)

        # æ„å»ºæŠ¥å‘Šå°¾éƒ¨
        footer_lines = ["", "---", ""]
        provider = llm_analysis_result.get('provider')
        model = llm_analysis_result.get('model')
        if provider:
            footer_lines.append(f"*åˆ†æå¼•æ“: {provider} ({model or 'unknown'})*")

        footer_lines.extend([
            "",
            "*æœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒ*"
        ])
        footer_section = "\n".join(footer_lines)

        report_content = "\n".join(header_info) + cleaned_llm_output + "\n\n" + sources_section + footer_section

        # åº”ç”¨æ¥æºé“¾æ¥å¢å¼ºåå¤„ç†
        report_content = self._enhance_source_links(report_content, sources)

        # ç®€å•å­£åº¦æ ‡é¢˜
        q = (end_time.month - 1) // 3 + 1
        title = f"å³åˆ»å­£åº¦æˆ˜ç•¥å™äº‹ - {display_name} - {end_time.year} Q{q}"
        report_row = {
            'report_type': 'quarterly_narrative',
            'scope': 'global',
            'analysis_period_start': start_time,
            'analysis_period_end': end_time,
            'items_analyzed': len(posts),
            'report_title': title,
            'report_content': report_content,
        }
        report_id = self.db.save_report(report_row)

        model_report = {
            'model': model_name,
            'model_display': display_name,
            'success': True,
            'report_id': report_id,
            'report_title': title,
            'provider': llm_analysis_result.get('provider') if llm_analysis_result else None,
            'items_analyzed': len(posts)
        }

        # å°è¯•æ¨é€åˆ°Notion
        notion_push_info = None
        try:
            from .notion_client import jike_notion_client

            # æ ¼å¼åŒ–Notionæ ‡é¢˜
            beijing_time = self._bj_time()
            notion_title = f"[{display_name}] å³åˆ»å­£åº¦æˆ˜ç•¥å™äº‹ - {end_time.year}Q{q} ({len(posts)}æ¡åŠ¨æ€)"

            self.logger.info(f"å¼€å§‹æ¨é€å­£æŠ¥åˆ°Notion ({display_name}): {notion_title}")

            notion_result = jike_notion_client.create_report_page(
                report_title=notion_title,
                report_content=report_content,
                report_date=beijing_time
            )

            if notion_result.get('success'):
                self.logger.info(f"å­£æŠ¥æˆåŠŸæ¨é€åˆ°Notion ({display_name}): {notion_result.get('page_url')}")
                notion_push_info = {
                    'success': True,
                    'page_url': notion_result.get('page_url'),
                    'path': notion_result.get('path')
                }
            else:
                error_msg = notion_result.get('error', 'æœªçŸ¥é”™è¯¯')
                self.logger.warning(f"æ¨é€å­£æŠ¥åˆ°Notionå¤±è´¥ ({display_name}): {error_msg}")
                notion_push_info = {
                    'success': False,
                    'error': error_msg
                }

        except Exception as e:
            self.logger.warning(f"æ¨é€å­£æŠ¥åˆ°Notionæ—¶å‡ºé”™ ({display_name}): {e}")
            notion_push_info = {
                'success': False,
                'error': str(e)
            }

        if notion_push_info:
            model_report['notion_push'] = notion_push_info

        return model_report

    async def generate_kol_trajectory(self, kol_ids: Optional[List[str]] = None, days_back: Optional[int] = None) -> Dict[str, Any]:
        """ä¸ºå¤šä¸ªKOLç”ŸæˆæŒ‰äººç»´åº¦çš„æ€æƒ³è½¨è¿¹å›¾ï¼ˆæ”¯æŒå¤šæ¨¡å‹å¹¶å‘å¤„ç†ï¼‰ã€‚è¿”å›ç»Ÿè®¡ç»“æœã€‚"""
        ids = kol_ids or self.analysis_cfg.get('kol_user_ids') or []
        days = int(days_back or self.analysis_cfg.get('days_back_kol', 30))
        if not ids:
            return {'success': False, 'error': 'æœªæä¾›KOLç”¨æˆ·IDåˆ—è¡¨'}

        end_time_global = self._bj_time()
        start_time_global = end_time_global - timedelta(days=days)

        # è·å–è¦ä½¿ç”¨çš„æ¨¡å‹åˆ—è¡¨
        models_to_generate = self._get_report_models()
        if not models_to_generate:
            self.logger.warning("æœªé…ç½®ä»»ä½•å¯ç”¨äºç”ŸæˆæŠ¥å‘Šçš„æ¨¡å‹")
            return {
                'success': False,
                'error': 'æœªé…ç½®å¯ç”¨çš„LLMæ¨¡å‹',
                'kol_reports': [],
                'total_generated': 0,
                'total_failed': 0
            }

        self.logger.info(f"å¼€å§‹ä¸º {len(ids)} ä¸ªKOLç”Ÿæˆæ€æƒ³è½¨è¿¹å›¾ï¼Œä½¿ç”¨æ¨¡å‹: {[self._get_model_display_name(m) for m in models_to_generate]}")

        kol_reports = []
        total_generated = 0
        total_failed = 0

        # ä¸ºæ¯ä¸ªKOLåˆ›å»ºå¹¶è¡Œä»»åŠ¡
        tasks = []
        task_meta = []

        for kol_id in ids:
            task_meta.append({'kol_id': kol_id})
            tasks.append(
                self._generate_kol_trajectory_for_user(
                    kol_id=kol_id,
                    models_to_generate=models_to_generate,
                    days=days,
                    start_time=start_time_global,
                    end_time=end_time_global
                )
            )

        self.logger.info(f"å¼€å§‹å¹¶è¡Œç”Ÿæˆ {len(tasks)} ä¸ªKOLçš„æŠ¥å‘Š")

        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰KOLä»»åŠ¡
        task_results = await asyncio.gather(*tasks, return_exceptions=True)

        # å¤„ç†ä»»åŠ¡ç»“æœ
        for meta, task_result in zip(task_meta, task_results):
            kol_id = meta['kol_id']

            if isinstance(task_result, Exception):
                error_msg = str(task_result)
                self.logger.warning(f"KOL {kol_id} æŠ¥å‘Šç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°æœªå¤„ç†å¼‚å¸¸: {error_msg}")
                kol_reports.append({
                    'kol_id': kol_id,
                    'success': False,
                    'error': error_msg,
                    'model_reports': [],
                    'failures': [{'error': error_msg}]
                })
                total_failed += 1
                continue

            if task_result.get('success'):
                kol_reports.append(task_result)
                total_generated += len(task_result.get('model_reports', []))
            else:
                kol_reports.append(task_result)
                total_failed += 1

        self.logger.info(f"KOLæŠ¥å‘Šç”Ÿæˆå®Œæˆ: æˆåŠŸç”Ÿæˆ {total_generated} ä»½æŠ¥å‘Šï¼Œå¤±è´¥ {total_failed} ä»½")

        return {
            'success': True,
            'kol_reports': kol_reports,
            'total_generated': total_generated,
            'total_failed': total_failed,
            'models_used': [self._get_model_display_name(m) for m in models_to_generate]
        }

    async def _generate_kol_trajectory_for_user(
        self,
        *,
        kol_id: str,
        models_to_generate: List[str],
        days: int,
        start_time: datetime,
        end_time: datetime
    ) -> Dict[str, Any]:
        """ä¸ºå•ä¸ªKOLç”Ÿæˆå¤šæ¨¡å‹æŠ¥å‘Š"""
        try:
            posts = self.db.get_user_posts_for_analysis(jike_user_id=kol_id, days=days)
            if not posts:
                self.logger.info(f"KOL {kol_id} æ— ç´ æï¼Œè·³è¿‡")
                return {
                    'kol_id': kol_id,
                    'success': False,
                    'error': 'KOLæ— ç´ ææ•°æ®',
                    'model_reports': [],
                    'failures': []
                }

            content_md, sources = self._format_posts_for_llm(posts, source_prefix='T')

            model_reports = []
            failures = []
            tasks = []
            task_meta = []

            # ä¸ºæ¯ä¸ªæ¨¡å‹åˆ›å»ºå¹¶è¡Œä»»åŠ¡
            for model_name in models_to_generate:
                display_name = self._get_model_display_name(model_name)
                task_meta.append({'model': model_name, 'display': display_name})
                tasks.append(
                    self._generate_kol_report_for_model(
                        kol_id=kol_id,
                        model_name=model_name,
                        display_name=display_name,
                        posts=posts,
                        content_md=content_md,
                        sources=sources,
                        start_time=start_time,
                        end_time=end_time
                    )
                )

            # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰æ¨¡å‹ä»»åŠ¡
            task_results = await asyncio.gather(*tasks, return_exceptions=True)

            # å¤„ç†ä»»åŠ¡ç»“æœ
            for meta, task_result in zip(task_meta, task_results):
                model_name = meta['model']
                display_name = meta['display']

                if isinstance(task_result, Exception):
                    error_msg = str(task_result)
                    self.logger.warning(f"KOL {kol_id} æ¨¡å‹ {model_name} ({display_name}) ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {error_msg}")
                    failures.append({
                        'model': model_name,
                        'model_display': display_name,
                        'error': error_msg
                    })
                    continue

                if task_result.get('success'):
                    model_reports.append(task_result)
                else:
                    failure_entry = {
                        'model': model_name,
                        'model_display': display_name,
                        'error': task_result.get('error', 'æŠ¥å‘Šç”Ÿæˆå¤±è´¥')
                    }
                    failures.append(failure_entry)

            overall_success = len(model_reports) > 0
            result = {
                'kol_id': kol_id,
                'success': overall_success,
                'items_analyzed': len(posts) if overall_success else 0,
                'model_reports': model_reports,
                'failures': failures
            }

            if overall_success:
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªæˆåŠŸçš„æŠ¥å‘Šä½œä¸ºä¸»è¦ç»“æœ
                primary_report = model_reports[0]
                result['primary_report_id'] = primary_report['report_id']
                result['primary_title'] = primary_report['report_title']
                result['report_ids'] = [mr['report_id'] for mr in model_reports]

            return result

        except Exception as e:
            error_msg = f"KOL {kol_id} æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}"
            self.logger.error(error_msg)
            return {
                'kol_id': kol_id,
                'success': False,
                'error': error_msg,
                'model_reports': [],
                'failures': [{'error': error_msg}]
            }

    async def _generate_kol_report_for_model(
        self,
        *,
        kol_id: str,
        model_name: str,
        display_name: str,
        posts: List[Dict[str, Any]],
        content_md: str,
        sources: List[Dict[str, Any]],
        start_time: datetime,
        end_time: datetime
    ) -> Dict[str, Any]:
        """åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­ä¸ºæŒ‡å®šæ¨¡å‹ç”ŸæˆKOLæŠ¥å‘Š"""
        return await asyncio.to_thread(
            self._generate_kol_report_for_model_sync,
            kol_id,
            model_name,
            display_name,
            posts,
            content_md,
            sources,
            start_time,
            end_time
        )

    def _generate_kol_report_for_model_sync(
        self,
        kol_id: str,
        model_name: str,
        display_name: str,
        posts: List[Dict[str, Any]],
        content_md: str,
        sources: List[Dict[str, Any]],
        start_time: datetime,
        end_time: datetime
    ) -> Dict[str, Any]:
        """åŒæ­¥æ‰§è¡ŒæŒ‡å®šæ¨¡å‹çš„KOLæŠ¥å‘Šç”Ÿæˆå’ŒNotionæ¨é€"""

        self.logger.info(f"[{display_name}] å¼€å§‹ä¸ºKOL {kol_id} ç”Ÿæˆæ€æƒ³è½¨è¿¹å›¾")

        # å¤ç”¨å‘¨æŠ¥æç¤ºè¯
        llm_analysis_result = self._analyze_with_llm(content_md, self._prompt_weekly(), model_override=model_name)

        if not llm_analysis_result:
            error_msg = f"LLMåˆ†æå¤±è´¥ï¼Œæœªç”ŸæˆKOLæŠ¥å‘Š ({kol_id})"
            self.logger.warning(f"[{display_name}] {error_msg}")
            return {
                'success': False,
                'error': error_msg,
                'model': model_name,
                'model_display': display_name,
                'kol_id': kol_id
            }

        llm_output = llm_analysis_result.get('content', '')
        # ä¸ºLLMç”Ÿæˆçš„æŠ¥å‘Šæ·»åŠ æ ‡å‡†å¤´éƒ¨ä¿¡æ¯
        beijing_time = self._bj_time()
        header_info = [
            f"# ğŸ¯ å³åˆ»KOLæ€æƒ³è½¨è¿¹ - {display_name} - {kol_id}",
            "",
            f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {beijing_time.strftime('%Y-%m-%d %H:%M:%S')}*  ",
            "",
            f"*æ•°æ®èŒƒå›´: {start_time.strftime('%Y-%m-%d %H:%M:%S')} - {end_time.strftime('%Y-%m-%d %H:%M:%S')}*  ",
            "",
            f"*åˆ†æåŠ¨æ€æ•°: {len(posts)} æ¡*",
            "",
            "---",
            ""
        ]

        # æ¸…ç†LLMè¾“å‡ºä¸­å¯èƒ½çš„æ ¼å¼é—®é¢˜
        cleaned_llm_output = self._clean_llm_output_for_notion(llm_output)

        sources_section = self._render_sources_section(sources)

        # æ„å»ºæŠ¥å‘Šå°¾éƒ¨
        footer_lines = ["", "---", ""]
        provider = llm_analysis_result.get('provider')
        model = llm_analysis_result.get('model')
        if provider:
            footer_lines.append(f"*åˆ†æå¼•æ“: {provider} ({model or 'unknown'})*")

        footer_lines.extend([
            "",
            "*æœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒ*"
        ])
        footer_section = "\n".join(footer_lines)

        report_content = "\n".join(header_info) + cleaned_llm_output + "\n\n" + sources_section + footer_section

        # åº”ç”¨æ¥æºé“¾æ¥å¢å¼ºåå¤„ç†
        report_content = self._enhance_source_links(report_content, sources)

        title = f"KOLæ€æƒ³è½¨è¿¹ - {display_name} - {kol_id} - æˆªæ­¢ {end_time.strftime('%Y-%m-%d')}"
        report_row = {
            'report_type': 'kol_trajectory',
            'scope': f'kol:{kol_id}',
            'analysis_period_start': start_time,
            'analysis_period_end': end_time,
            'items_analyzed': len(posts),
            'report_title': title,
            'report_content': report_content,
        }
        report_id = self.db.save_report(report_row)

        model_report = {
            'model': model_name,
            'model_display': display_name,
            'success': True,
            'report_id': report_id,
            'report_title': title,
            'provider': llm_analysis_result.get('provider') if llm_analysis_result else None,
            'items_analyzed': len(posts),
            'kol_id': kol_id
        }

        # å°è¯•æ¨é€KOLæŠ¥å‘Šåˆ°Notion
        notion_push_info = None
        try:
            from .notion_client import jike_notion_client

            # æ ¼å¼åŒ–Notionæ ‡é¢˜
            beijing_time = self._bj_time()
            notion_title = f"[{display_name}] KOLæ€æƒ³è½¨è¿¹ - {kol_id} - {beijing_time.strftime('%Y%m%d')} ({len(posts)}æ¡åŠ¨æ€)"

            self.logger.info(f"å¼€å§‹æ¨é€KOLæŠ¥å‘Šåˆ°Notion ({display_name}): {notion_title}")

            notion_result = jike_notion_client.create_report_page(
                report_title=notion_title,
                report_content=report_content,
                report_date=beijing_time
            )

            if notion_result.get('success'):
                self.logger.info(f"KOLæŠ¥å‘ŠæˆåŠŸæ¨é€åˆ°Notion ({display_name}): {notion_result.get('page_url')}")
                notion_push_info = {
                    'success': True,
                    'page_url': notion_result.get('page_url'),
                    'path': notion_result.get('path')
                }
            else:
                error_msg = notion_result.get('error', 'æœªçŸ¥é”™è¯¯')
                self.logger.warning(f"æ¨é€KOLæŠ¥å‘Šåˆ°Notionå¤±è´¥ ({display_name}): {error_msg}")
                notion_push_info = {
                    'success': False,
                    'error': error_msg
                }

        except Exception as e:
            self.logger.warning(f"æ¨é€KOLæŠ¥å‘Šåˆ°Notionæ—¶å‡ºé”™ ({display_name}): {e}")
            notion_push_info = {
                'success': False,
                'error': str(e)
            }

        if notion_push_info:
            model_report['notion_push'] = notion_push_info

        return model_report


def get_report_generator() -> JKReportGenerator:
    """æ¨¡å—çº§å·¥å‚å‡½æ•°ï¼Œä¾›taskså»¶è¿Ÿå¯¼å…¥è°ƒç”¨"""
    return JKReportGenerator()


# ===== ä¾¿æ·å‡½æ•°ï¼Œä¾›tasks.pyè°ƒç”¨ =====

def run_light_reports(hours: Optional[int] = None) -> Dict[str, Any]:
    """ç”Ÿæˆæ—¥æŠ¥èµ„è®¯çš„ä¾¿æ·å‡½æ•°"""
    rg = get_report_generator()
    return asyncio.run(rg.generate_light_reports(hours_back=hours))


def run_deep_reports(hours: Optional[int] = None) -> Dict[str, Any]:
    """ç”Ÿæˆçƒ­ç‚¹è¿½è¸ªçš„ä¾¿æ·å‡½æ•°"""
    rg = get_report_generator()
    return asyncio.run(rg.generate_deep_reports(hours_back=hours))


def run_dual_reports(hours: Optional[int] = None) -> Dict[str, Any]:
    """è¿è¡ŒåŒè½¨åˆ¶æŠ¥å‘Šçš„ä¾¿æ·å‡½æ•°"""
    rg = get_report_generator()
    return asyncio.run(rg.run_dual_report_generation(hours_back=hours))
